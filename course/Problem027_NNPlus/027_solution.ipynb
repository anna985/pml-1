{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "colab": {
      "name": "Copy of 027_solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna985/pml-1/blob/master/course/Problem027_NNPlus/027_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwakg9Jdrmpl"
      },
      "source": [
        "## Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdXtVOSArmpr"
      },
      "source": [
        "## TBD Doing better on Fashion MNIST dataset using CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btNd0Lh_rmpr"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalized features\n",
        "X_train = X_train.reshape(60000,28,28,1)/255.0\n",
        "X_test = X_test.reshape(10000,28,28,1)/255.0\n",
        "\n",
        "# Encode Y as binary class vector\n",
        "Y_train = np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = np_utils.to_categorical(Y_test, 10)\n",
        "\n",
        "# TBD: Use following architecture to classify fashion MNIST dataset\n",
        "# activation function is relu for all layers except last where its softmax\n",
        "# 1 Convolutional Layer (filters = 64, kernel_size = 4 )\n",
        "# 2 Convolutional Layer (filters = 64, kernel_size = 4)\n",
        "# 3 Max Pooling Layer (size 2)\n",
        "# 4 Convolutional Layer (filters = 128, kernel_size = 3)\n",
        "# 5 Convolutional Layer (filters = 128, kernel_size = 3)\n",
        "# 6 Max Pooling Layer (size 2)\n",
        "# 7 Dense Layer (64 neurons)\n",
        "# 8 Dense Layer (10 neurons, activation = softmax)\n",
        "model = Sequential([\n",
        "    Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n",
        "    Conv2D(64, 4, activation=\"relu\", padding=\"same\"),\n",
        "    MaxPooling2D(2),\n",
        "    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    MaxPooling2D(2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=100, epochs=10, verbose=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8vwpVEeQrmps"
      },
      "source": [
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atQUP89Zrmpt"
      },
      "source": [
        "## Recurrent Neural Networks(RNNs) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXQtYvzBrmpt"
      },
      "source": [
        "## Sequence Prediction\n",
        "\n",
        "## Simple RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eNYdsa8ormpt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "def ts2XY(ts, n):\n",
        "    '''\n",
        "    Generates a features and labels from a timeseries sequence\n",
        "    ignores the timestamp, just arranges the sequence\n",
        "    into n features by shifting 1 for each feature\n",
        "    also removes the rows which have NaN due to shifting (first n  rows)\n",
        "    (no error handling for now)\n",
        "    :param ts: univariate timeseries dataframe, with a 'value' column\n",
        "    :param n: number of features\n",
        "    :return: X , Y\n",
        "    '''\n",
        "\n",
        "    X = pd.concat(\n",
        "          [\n",
        "            ts['value'].shift(i).rename(f'feature_{i}')\n",
        "              for i in range(1, n+1)\n",
        "          ], axis = 1)\n",
        "\n",
        "    Y = ts['value'][:].to_frame()\n",
        "    Y = ts['value'][n:].to_frame()\n",
        "    X = X[n:]\n",
        "    return X,Y\n",
        "\n",
        "\n",
        "\n",
        "def evalts(ts, lookback, scaler, metric, test_size=0.25):\n",
        "\n",
        "    if scaler is not None:\n",
        "        ts['value'] = scaler.fit_transform(ts['value'].to_frame())\n",
        "\n",
        "    X,Y = ts2XY(ts, lookback)\n",
        "\n",
        "    assert(len(X) == len(Y) and 0.0 <= test_size <= 1.0 )\n",
        "\n",
        "    f = int(len(X)*test_size)\n",
        "\n",
        "    X_train,X_test,Y_train,Y_test = X[:f],X[f:],Y[:f],Y[f:] #because we want to preserve the order\n",
        "\n",
        "    Y_hat1 = X_test.iloc[:, -1]\n",
        "    print(f\"model1 (last observation) {metric.__name__} = {metric(Y_test, Y_hat1)}\")\n",
        "\n",
        "    Y_hat2 = X_test.mean(axis=1)\n",
        "    print(f\"model2 (mean of lookback observations) {metric.__name__} = {metric(Y_test, Y_hat2)}\")\n",
        "\n",
        "    model3 = LinearRegression()\n",
        "    model3.fit(X_train, Y_train)\n",
        "    Y_hat3 = model3.predict(X_test)\n",
        "    print(f\"model3 (Linear regression) {metric.__name__} = {metric(Y_test, Y_hat3)}\")\n",
        "\n",
        "    model4 = Sequential([\n",
        "      SimpleRNN(1, input_shape=[None, 1])\n",
        "    ])\n",
        "\n",
        "    model4.compile(loss=\"mse\", optimizer=SGD(lr=0.01, momentum=0.9))\n",
        "    X_train_ts = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    model4.fit(X_train_ts, Y_train, epochs=100, verbose=0)\n",
        "    Y_hat4 = model4.predict(np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1))\n",
        "    print(f\"model4 (RNN 1) {metric.__name__} = {metric(Y_test, Y_hat4)}\")\n",
        "\n",
        "    model5 = Sequential([\n",
        "        SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "        SimpleRNN(20, return_sequences=True),\n",
        "        SimpleRNN(1)\n",
        "        # SimpleRNN(20),\n",
        "        # Dense(1, activation='relu')\n",
        "    ])\n",
        "\n",
        "    model5.compile(loss=\"mse\", optimizer=SGD(lr=0.01, momentum=0.9))\n",
        "    model5.fit(X_train_ts, Y_train, epochs=10, verbose=0)\n",
        "    Y_hat5 = model5.predict(np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1))\n",
        "    print(f\"model5 (RNN n) {metric.__name__} = {metric(Y_test, Y_hat5)}\")\n",
        "\n",
        "ts = pd.read_csv('https://raw.githubusercontent.com/numenta/NAB/master/data/artificialNoAnomaly/art_daily_no_noise.csv')\n",
        "evalts(ts, 7, MinMaxScaler(), mean_squared_error)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}