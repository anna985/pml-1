{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "colab": {
      "name": "Copy of Copy of 026_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna985/pml-1/blob/master/course/Problem026_NNLibrary/026_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdI2BAoHr6BX"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "from numpy.random import seed\n",
        "seed(101)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwzdP-xCr6Bd"
      },
      "source": [
        "## sklearn MNIST(8X8) dataset with dense NN using keras (Same as problem 25)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "id": "FvQjiPq-r6Bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd475d8b-724b-4cfc-d2c7-d946f00b0465"
      },
      "source": [
        "# Preparing the digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "X = digits.data\n",
        "\n",
        "# One hot encoding of target (Y)\n",
        "Y = np_utils.to_categorical(digits.target, 10)\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "# Model Architecture [(64, None), (40, relu), (20, relu), (10, sigmoid)]\n",
        "model = Sequential()\n",
        "model.add(Dense(40, activation='relu', input_shape=(64,)))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "#Model hyperparams. (though architecture also is a hyperparam)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=SGD(lr=0.01, momentum=0.9),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, Y_train,\n",
        "            batch_size=len(X_train), epochs=100,\n",
        "            verbose=1, validation_split=0.2)\n",
        "\n",
        "# Testing the model\n",
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "\n",
        "print(\"Test loss:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 40)                2600      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 3,630\n",
            "Trainable params: 3,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.9513 - accuracy: 0.0669 - val_loss: 5.3116 - val_accuracy: 0.1037\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.2623 - accuracy: 0.0864 - val_loss: 4.2771 - val_accuracy: 0.0926\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.3110 - accuracy: 0.0743 - val_loss: 3.0009 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0382 - accuracy: 0.0826 - val_loss: 2.5758 - val_accuracy: 0.1481\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.6091 - accuracy: 0.1235 - val_loss: 2.3398 - val_accuracy: 0.1556\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3406 - accuracy: 0.1643 - val_loss: 2.1473 - val_accuracy: 0.2037\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1143 - accuracy: 0.2331 - val_loss: 2.0909 - val_accuracy: 0.2111\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0497 - accuracy: 0.2451 - val_loss: 2.0911 - val_accuracy: 0.2519\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 2.0475 - accuracy: 0.2739 - val_loss: 2.0568 - val_accuracy: 0.2704\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0133 - accuracy: 0.2999 - val_loss: 1.9639 - val_accuracy: 0.3111\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.9300 - accuracy: 0.3445 - val_loss: 1.8444 - val_accuracy: 0.3630\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8232 - accuracy: 0.3742 - val_loss: 1.7224 - val_accuracy: 0.4148\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.7128 - accuracy: 0.4308 - val_loss: 1.6119 - val_accuracy: 0.4593\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.6115 - accuracy: 0.4522 - val_loss: 1.5351 - val_accuracy: 0.4778\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5257 - accuracy: 0.4726 - val_loss: 1.5022 - val_accuracy: 0.4741\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4693 - accuracy: 0.4949 - val_loss: 1.4734 - val_accuracy: 0.4778\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4201 - accuracy: 0.5135 - val_loss: 1.4106 - val_accuracy: 0.4963\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.3435 - accuracy: 0.5422 - val_loss: 1.3250 - val_accuracy: 0.5407\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2504 - accuracy: 0.5645 - val_loss: 1.2549 - val_accuracy: 0.5630\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.1819 - accuracy: 0.5831 - val_loss: 1.2020 - val_accuracy: 0.5667\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1381 - accuracy: 0.5961 - val_loss: 1.1468 - val_accuracy: 0.5778\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0918 - accuracy: 0.6091 - val_loss: 1.0777 - val_accuracy: 0.5926\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0248 - accuracy: 0.6277 - val_loss: 1.0075 - val_accuracy: 0.6370\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9493 - accuracy: 0.6602 - val_loss: 0.9655 - val_accuracy: 0.6889\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8949 - accuracy: 0.6852 - val_loss: 0.9482 - val_accuracy: 0.6889\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.8640 - accuracy: 0.7047 - val_loss: 0.9190 - val_accuracy: 0.7037\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8244 - accuracy: 0.7187 - val_loss: 0.8592 - val_accuracy: 0.7259\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.7647 - accuracy: 0.7447 - val_loss: 0.7946 - val_accuracy: 0.7407\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7117 - accuracy: 0.7586 - val_loss: 0.7493 - val_accuracy: 0.7556\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6789 - accuracy: 0.7688 - val_loss: 0.7138 - val_accuracy: 0.7593\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6488 - accuracy: 0.7623 - val_loss: 0.6801 - val_accuracy: 0.7704\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6118 - accuracy: 0.7818 - val_loss: 0.6539 - val_accuracy: 0.8000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5782 - accuracy: 0.8022 - val_loss: 0.6321 - val_accuracy: 0.8037\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5481 - accuracy: 0.8152 - val_loss: 0.6061 - val_accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5170 - accuracy: 0.8310 - val_loss: 0.5765 - val_accuracy: 0.8000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4889 - accuracy: 0.8329 - val_loss: 0.5492 - val_accuracy: 0.8037\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4692 - accuracy: 0.8384 - val_loss: 0.5214 - val_accuracy: 0.8222\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4514 - accuracy: 0.8505 - val_loss: 0.4908 - val_accuracy: 0.8333\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.4298 - accuracy: 0.8561 - val_loss: 0.4643 - val_accuracy: 0.8370\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4080 - accuracy: 0.8635 - val_loss: 0.4479 - val_accuracy: 0.8370\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3936 - accuracy: 0.8672 - val_loss: 0.4375 - val_accuracy: 0.8481\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3824 - accuracy: 0.8691 - val_loss: 0.4242 - val_accuracy: 0.8556\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3660 - accuracy: 0.8756 - val_loss: 0.4078 - val_accuracy: 0.8630\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3461 - accuracy: 0.8802 - val_loss: 0.3944 - val_accuracy: 0.8667\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3298 - accuracy: 0.8932 - val_loss: 0.3845 - val_accuracy: 0.8852\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3182 - accuracy: 0.8951 - val_loss: 0.3750 - val_accuracy: 0.8889\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3076 - accuracy: 0.8942 - val_loss: 0.3647 - val_accuracy: 0.8926\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2966 - accuracy: 0.9034 - val_loss: 0.3553 - val_accuracy: 0.8889\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2863 - accuracy: 0.9081 - val_loss: 0.3453 - val_accuracy: 0.8852\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2771 - accuracy: 0.9081 - val_loss: 0.3329 - val_accuracy: 0.8889\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2679 - accuracy: 0.9109 - val_loss: 0.3197 - val_accuracy: 0.8963\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2590 - accuracy: 0.9127 - val_loss: 0.3091 - val_accuracy: 0.9185\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2516 - accuracy: 0.9174 - val_loss: 0.3009 - val_accuracy: 0.9259\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2447 - accuracy: 0.9211 - val_loss: 0.2936 - val_accuracy: 0.9222\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2369 - accuracy: 0.9304 - val_loss: 0.2867 - val_accuracy: 0.9222\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2286 - accuracy: 0.9341 - val_loss: 0.2804 - val_accuracy: 0.9222\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2213 - accuracy: 0.9369 - val_loss: 0.2746 - val_accuracy: 0.9296\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2149 - accuracy: 0.9396 - val_loss: 0.2691 - val_accuracy: 0.9296\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2086 - accuracy: 0.9424 - val_loss: 0.2635 - val_accuracy: 0.9259\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2024 - accuracy: 0.9443 - val_loss: 0.2587 - val_accuracy: 0.9259\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.1964 - accuracy: 0.9452 - val_loss: 0.2553 - val_accuracy: 0.9296\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1907 - accuracy: 0.9443 - val_loss: 0.2529 - val_accuracy: 0.9259\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1848 - accuracy: 0.9424 - val_loss: 0.2514 - val_accuracy: 0.9296\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1791 - accuracy: 0.9461 - val_loss: 0.2504 - val_accuracy: 0.9296\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1741 - accuracy: 0.9517 - val_loss: 0.2496 - val_accuracy: 0.9296\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1697 - accuracy: 0.9545 - val_loss: 0.2481 - val_accuracy: 0.9296\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1654 - accuracy: 0.9564 - val_loss: 0.2454 - val_accuracy: 0.9296\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1611 - accuracy: 0.9564 - val_loss: 0.2421 - val_accuracy: 0.9296\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1569 - accuracy: 0.9582 - val_loss: 0.2387 - val_accuracy: 0.9296\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1530 - accuracy: 0.9573 - val_loss: 0.2353 - val_accuracy: 0.9259\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1493 - accuracy: 0.9591 - val_loss: 0.2322 - val_accuracy: 0.9259\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1457 - accuracy: 0.9591 - val_loss: 0.2292 - val_accuracy: 0.9296\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1422 - accuracy: 0.9629 - val_loss: 0.2263 - val_accuracy: 0.9296\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1388 - accuracy: 0.9629 - val_loss: 0.2233 - val_accuracy: 0.9296\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1355 - accuracy: 0.9629 - val_loss: 0.2199 - val_accuracy: 0.9296\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1323 - accuracy: 0.9647 - val_loss: 0.2165 - val_accuracy: 0.9370\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1291 - accuracy: 0.9647 - val_loss: 0.2130 - val_accuracy: 0.9370\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1262 - accuracy: 0.9666 - val_loss: 0.2097 - val_accuracy: 0.9407\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1235 - accuracy: 0.9675 - val_loss: 0.2064 - val_accuracy: 0.9407\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1209 - accuracy: 0.9675 - val_loss: 0.2034 - val_accuracy: 0.9444\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1183 - accuracy: 0.9684 - val_loss: 0.2008 - val_accuracy: 0.9444\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1158 - accuracy: 0.9694 - val_loss: 0.1986 - val_accuracy: 0.9444\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1134 - accuracy: 0.9703 - val_loss: 0.1965 - val_accuracy: 0.9444\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1111 - accuracy: 0.9703 - val_loss: 0.1945 - val_accuracy: 0.9407\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1089 - accuracy: 0.9712 - val_loss: 0.1925 - val_accuracy: 0.9407\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1068 - accuracy: 0.9721 - val_loss: 0.1905 - val_accuracy: 0.9444\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1048 - accuracy: 0.9721 - val_loss: 0.1885 - val_accuracy: 0.9444\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1028 - accuracy: 0.9731 - val_loss: 0.1866 - val_accuracy: 0.9444\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1008 - accuracy: 0.9731 - val_loss: 0.1847 - val_accuracy: 0.9444\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0990 - accuracy: 0.9740 - val_loss: 0.1830 - val_accuracy: 0.9444\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0972 - accuracy: 0.9749 - val_loss: 0.1815 - val_accuracy: 0.9444\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0954 - accuracy: 0.9759 - val_loss: 0.1802 - val_accuracy: 0.9444\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0937 - accuracy: 0.9759 - val_loss: 0.1789 - val_accuracy: 0.9444\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0921 - accuracy: 0.9768 - val_loss: 0.1777 - val_accuracy: 0.9444\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0904 - accuracy: 0.9768 - val_loss: 0.1766 - val_accuracy: 0.9444\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0889 - accuracy: 0.9777 - val_loss: 0.1755 - val_accuracy: 0.9444\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0874 - accuracy: 0.9777 - val_loss: 0.1744 - val_accuracy: 0.9444\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0859 - accuracy: 0.9777 - val_loss: 0.1734 - val_accuracy: 0.9444\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0845 - accuracy: 0.9796 - val_loss: 0.1722 - val_accuracy: 0.9444\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0830 - accuracy: 0.9805 - val_loss: 0.1711 - val_accuracy: 0.9444\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9400\n",
            "Test loss: 0.2145531326532364\n",
            "Test accuracy: 0.9399999976158142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juEc4e4tr6Be"
      },
      "source": [
        "## TBD: Use same Neural Network as above on standard MNIST dataset (28X28 = 784 pixels) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlIfgNHKr6Be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd1d21d-d40a-49b3-d8d4-9d412157572d"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "#Data: shuffled and split between train and test sets\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "# Normalized features\n",
        "X_train = X_train.reshape(60000, 28*28)/255.0\n",
        "X_test = X_test.reshape(10000, 28*28)/255.0\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# Encode Y as binary class vector\n",
        "Y_train = np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = np_utils.to_categorical(Y_test, 10)\n",
        "\n",
        "# TBD: Build a 3 layer [(784, None), (40, relu), (20, relu), (10, sigmoid)] Neural Network\n",
        "# using Keras, train it on X_train dataset, and compute accuracy and loss on test dataset.\n",
        "# Exactly same code as above (sklearn MNIST(8X8) Dataset) just change input_shape=(64,) to input_shape=(784,)\n",
        "# You should see 90%+ accuracy on test set\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(40, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "#Model hyperparams. (though architecture also is a hyperparam)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=SGD(lr=0.01, momentum=0.9),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, Y_train,\n",
        "            batch_size=len(X_train), epochs=100,\n",
        "            verbose=1, validation_split=0.2)\n",
        "\n",
        "# Testing the model\n",
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "\n",
        "print(\"Test loss:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 40)                31400     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 32,430\n",
            "Trainable params: 32,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 2.3614 - accuracy: 0.1215 - val_loss: 2.3542 - val_accuracy: 0.1189\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 2.3517 - accuracy: 0.1239 - val_loss: 2.3369 - val_accuracy: 0.1238\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 2.3345 - accuracy: 0.1290 - val_loss: 2.3150 - val_accuracy: 0.1328\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 2.3130 - accuracy: 0.1364 - val_loss: 2.2917 - val_accuracy: 0.1461\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 2.2900 - accuracy: 0.1475 - val_loss: 2.2689 - val_accuracy: 0.1616\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 2.2677 - accuracy: 0.1621 - val_loss: 2.2476 - val_accuracy: 0.1791\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 2.2469 - accuracy: 0.1788 - val_loss: 2.2278 - val_accuracy: 0.1962\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 2.2276 - accuracy: 0.1971 - val_loss: 2.2089 - val_accuracy: 0.2165\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 2.2091 - accuracy: 0.2159 - val_loss: 2.1899 - val_accuracy: 0.2352\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 2.1905 - accuracy: 0.2347 - val_loss: 2.1702 - val_accuracy: 0.2547\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 2.1712 - accuracy: 0.2519 - val_loss: 2.1494 - val_accuracy: 0.2693\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 2.1509 - accuracy: 0.2666 - val_loss: 2.1273 - val_accuracy: 0.2828\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 2.1293 - accuracy: 0.2790 - val_loss: 2.1043 - val_accuracy: 0.2928\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 2.1067 - accuracy: 0.2886 - val_loss: 2.0806 - val_accuracy: 0.2992\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 2.0836 - accuracy: 0.2963 - val_loss: 2.0568 - val_accuracy: 0.3033\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 2.0601 - accuracy: 0.3010 - val_loss: 2.0329 - val_accuracy: 0.3050\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 2.0367 - accuracy: 0.3044 - val_loss: 2.0090 - val_accuracy: 0.3077\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 2.0133 - accuracy: 0.3075 - val_loss: 1.9848 - val_accuracy: 0.3137\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 1.9898 - accuracy: 0.3124 - val_loss: 1.9600 - val_accuracy: 0.3215\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 1.9656 - accuracy: 0.3187 - val_loss: 1.9343 - val_accuracy: 0.3299\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 1.9406 - accuracy: 0.3278 - val_loss: 1.9075 - val_accuracy: 0.3399\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 1.9145 - accuracy: 0.3376 - val_loss: 1.8797 - val_accuracy: 0.3537\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 1.8873 - accuracy: 0.3499 - val_loss: 1.8512 - val_accuracy: 0.3682\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 1.8594 - accuracy: 0.3644 - val_loss: 1.8222 - val_accuracy: 0.3846\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 1.8310 - accuracy: 0.3799 - val_loss: 1.7932 - val_accuracy: 0.3997\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 1.8025 - accuracy: 0.3943 - val_loss: 1.7642 - val_accuracy: 0.4162\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 1.7741 - accuracy: 0.4095 - val_loss: 1.7355 - val_accuracy: 0.4320\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 1.7459 - accuracy: 0.4245 - val_loss: 1.7070 - val_accuracy: 0.4457\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 1.7180 - accuracy: 0.4400 - val_loss: 1.6787 - val_accuracy: 0.4605\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 1.6903 - accuracy: 0.4547 - val_loss: 1.6505 - val_accuracy: 0.4757\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 1.6627 - accuracy: 0.4686 - val_loss: 1.6224 - val_accuracy: 0.4902\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 1.6351 - accuracy: 0.4828 - val_loss: 1.5942 - val_accuracy: 0.5027\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 1.6073 - accuracy: 0.4964 - val_loss: 1.5659 - val_accuracy: 0.5147\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 1.5795 - accuracy: 0.5088 - val_loss: 1.5376 - val_accuracy: 0.5272\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 1.5517 - accuracy: 0.5219 - val_loss: 1.5093 - val_accuracy: 0.5404\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 1.5238 - accuracy: 0.5344 - val_loss: 1.4811 - val_accuracy: 0.5522\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 1.4960 - accuracy: 0.5471 - val_loss: 1.4529 - val_accuracy: 0.5623\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 1.4683 - accuracy: 0.5582 - val_loss: 1.4250 - val_accuracy: 0.5750\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 1.4407 - accuracy: 0.5686 - val_loss: 1.3972 - val_accuracy: 0.5852\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 1.4132 - accuracy: 0.5791 - val_loss: 1.3694 - val_accuracy: 0.5942\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 1.3858 - accuracy: 0.5882 - val_loss: 1.3417 - val_accuracy: 0.6033\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 1.3585 - accuracy: 0.5973 - val_loss: 1.3141 - val_accuracy: 0.6128\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 1.3313 - accuracy: 0.6062 - val_loss: 1.2866 - val_accuracy: 0.6223\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 1.3043 - accuracy: 0.6142 - val_loss: 1.2592 - val_accuracy: 0.6300\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 1.2774 - accuracy: 0.6219 - val_loss: 1.2320 - val_accuracy: 0.6407\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 1.2508 - accuracy: 0.6300 - val_loss: 1.2049 - val_accuracy: 0.6490\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 1.2245 - accuracy: 0.6385 - val_loss: 1.1781 - val_accuracy: 0.6561\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 1.1984 - accuracy: 0.6456 - val_loss: 1.1515 - val_accuracy: 0.6653\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 1.1726 - accuracy: 0.6536 - val_loss: 1.1252 - val_accuracy: 0.6742\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 1.1471 - accuracy: 0.6621 - val_loss: 1.0991 - val_accuracy: 0.6847\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 1.1218 - accuracy: 0.6711 - val_loss: 1.0733 - val_accuracy: 0.6942\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 1.0968 - accuracy: 0.6816 - val_loss: 1.0479 - val_accuracy: 0.7032\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 1.0722 - accuracy: 0.6917 - val_loss: 1.0230 - val_accuracy: 0.7131\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 1.0482 - accuracy: 0.7013 - val_loss: 0.9987 - val_accuracy: 0.7258\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 1.0248 - accuracy: 0.7115 - val_loss: 0.9751 - val_accuracy: 0.7350\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 1.0021 - accuracy: 0.7211 - val_loss: 0.9524 - val_accuracy: 0.7450\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.9803 - accuracy: 0.7301 - val_loss: 0.9306 - val_accuracy: 0.7548\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.9594 - accuracy: 0.7385 - val_loss: 0.9098 - val_accuracy: 0.7610\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.9395 - accuracy: 0.7461 - val_loss: 0.8900 - val_accuracy: 0.7671\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.9205 - accuracy: 0.7515 - val_loss: 0.8712 - val_accuracy: 0.7721\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.9025 - accuracy: 0.7567 - val_loss: 0.8533 - val_accuracy: 0.7770\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.8854 - accuracy: 0.7610 - val_loss: 0.8362 - val_accuracy: 0.7814\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.8690 - accuracy: 0.7640 - val_loss: 0.8200 - val_accuracy: 0.7837\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.8534 - accuracy: 0.7675 - val_loss: 0.8044 - val_accuracy: 0.7859\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.8383 - accuracy: 0.7709 - val_loss: 0.7894 - val_accuracy: 0.7887\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.8238 - accuracy: 0.7741 - val_loss: 0.7750 - val_accuracy: 0.7918\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.8097 - accuracy: 0.7769 - val_loss: 0.7612 - val_accuracy: 0.7938\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.7961 - accuracy: 0.7795 - val_loss: 0.7478 - val_accuracy: 0.7966\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.7830 - accuracy: 0.7823 - val_loss: 0.7350 - val_accuracy: 0.7996\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.7704 - accuracy: 0.7851 - val_loss: 0.7228 - val_accuracy: 0.8018\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.7583 - accuracy: 0.7876 - val_loss: 0.7111 - val_accuracy: 0.8040\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7467 - accuracy: 0.7897 - val_loss: 0.7000 - val_accuracy: 0.8058\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.7357 - accuracy: 0.7915 - val_loss: 0.6894 - val_accuracy: 0.8070\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7253 - accuracy: 0.7935 - val_loss: 0.6794 - val_accuracy: 0.8086\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.7154 - accuracy: 0.7950 - val_loss: 0.6699 - val_accuracy: 0.8099\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.7060 - accuracy: 0.7966 - val_loss: 0.6607 - val_accuracy: 0.8115\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.6969 - accuracy: 0.7982 - val_loss: 0.6520 - val_accuracy: 0.8138\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.6883 - accuracy: 0.8002 - val_loss: 0.6435 - val_accuracy: 0.8160\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.6800 - accuracy: 0.8025 - val_loss: 0.6354 - val_accuracy: 0.8188\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.6720 - accuracy: 0.8042 - val_loss: 0.6276 - val_accuracy: 0.8204\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.6643 - accuracy: 0.8064 - val_loss: 0.6201 - val_accuracy: 0.8226\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.6569 - accuracy: 0.8086 - val_loss: 0.6129 - val_accuracy: 0.8246\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.6497 - accuracy: 0.8101 - val_loss: 0.6060 - val_accuracy: 0.8264\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.6429 - accuracy: 0.8117 - val_loss: 0.5993 - val_accuracy: 0.8280\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.6363 - accuracy: 0.8132 - val_loss: 0.5930 - val_accuracy: 0.8298\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.6300 - accuracy: 0.8147 - val_loss: 0.5869 - val_accuracy: 0.8320\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.6240 - accuracy: 0.8165 - val_loss: 0.5811 - val_accuracy: 0.8338\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.6181 - accuracy: 0.8182 - val_loss: 0.5755 - val_accuracy: 0.8348\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.6125 - accuracy: 0.8196 - val_loss: 0.5701 - val_accuracy: 0.8363\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.6071 - accuracy: 0.8210 - val_loss: 0.5650 - val_accuracy: 0.8372\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.6018 - accuracy: 0.8221 - val_loss: 0.5600 - val_accuracy: 0.8378\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.5968 - accuracy: 0.8236 - val_loss: 0.5553 - val_accuracy: 0.8390\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.5919 - accuracy: 0.8247 - val_loss: 0.5507 - val_accuracy: 0.8409\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.5872 - accuracy: 0.8259 - val_loss: 0.5463 - val_accuracy: 0.8423\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.5826 - accuracy: 0.8269 - val_loss: 0.5420 - val_accuracy: 0.8428\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.5781 - accuracy: 0.8282 - val_loss: 0.5379 - val_accuracy: 0.8443\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.5738 - accuracy: 0.8295 - val_loss: 0.5338 - val_accuracy: 0.8462\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.5697 - accuracy: 0.8303 - val_loss: 0.5299 - val_accuracy: 0.8475\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.5656 - accuracy: 0.8314 - val_loss: 0.5261 - val_accuracy: 0.8483\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.5617 - accuracy: 0.8327 - val_loss: 0.5224 - val_accuracy: 0.8493\n",
            "313/313 [==============================] - 0s 896us/step - loss: 0.5282 - accuracy: 0.8422\n",
            "Test loss: 0.5282096862792969\n",
            "Test accuracy: 0.842199981212616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdHmJT_Dr6Be"
      },
      "source": [
        "## NN Fashion\n",
        "## TBD: Use above Neural Network on Fashion MNIST  dataset (28X28 = 784 pixels) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Y6cvxTx5r6Bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cf643df-f385-4e0d-fcb0-0f5a8d05738a"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TBD Explore data (input shape, output shape) Fashion MNIST is a drop in replacement \n",
        "# for MNIST so shapes should be same. \n",
        "\n",
        "#TBD View the images (clothing types) and their labels \n",
        "\n",
        "# Show first K images\n",
        "K = 6\n",
        "plt.figure(figsize=(8,K))\n",
        "for i in range(K):\n",
        "    image, label = X_train[i], Y_train[i]\n",
        "    plt.subplot(1, K, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title('Label: %i' % label)\n",
        "\n",
        "# Normalized features\n",
        "X_train = X_train.reshape(60000, 28*28)/255.0\n",
        "X_test = X_test.reshape(10000, 28*28)/255.0\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# Encode Y as binary class vector\n",
        "Y_train = np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = np_utils.to_categorical(Y_test, 10)\n",
        "\n",
        "#TBD: Build a 3 layer [(784, None), (40, relu), (20, relu), (10, sigmoid)] Neural Network\n",
        "# using Keras, train it on X_train dataset, and compute accuracy and loss on test dataset.\n",
        "# Exactly same code as above (sklearn MNIST(8X8) Dataset) just change input_shape=(64,) to input_shape=(784,)\n",
        "# You should see 80%+ accuracy on test set, we will better this by using CNN\n",
        "\n",
        "# Model Architecture [(784, None), (40, relu), (20, relu), (10, sigmoid)]\n",
        "model = Sequential()\n",
        "model.add(Dense(40, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "#Model hyperparams. (though architecture also is a hyperparam)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=SGD(lr=0.01, momentum=0.9),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, Y_train,\n",
        "            batch_size=len(X_train), epochs=100,\n",
        "            verbose=1, validation_split=0.2)\n",
        "\n",
        "# Testing the model\n",
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "\n",
        "print(\"Test loss:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 40)                31400     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 32,430\n",
            "Trainable params: 32,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 2.4459 - accuracy: 0.0735 - val_loss: 2.3887 - val_accuracy: 0.0897\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 2.3936 - accuracy: 0.0882 - val_loss: 2.3186 - val_accuracy: 0.1213\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 407ms/step - loss: 2.3227 - accuracy: 0.1184 - val_loss: 2.2634 - val_accuracy: 0.1708\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 2.2666 - accuracy: 0.1663 - val_loss: 2.2300 - val_accuracy: 0.2227\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 2.2331 - accuracy: 0.2161 - val_loss: 2.2114 - val_accuracy: 0.2637\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 2.2140 - accuracy: 0.2597 - val_loss: 2.1931 - val_accuracy: 0.2760\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 2.1949 - accuracy: 0.2749 - val_loss: 2.1675 - val_accuracy: 0.2831\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 2.1690 - accuracy: 0.2851 - val_loss: 2.1387 - val_accuracy: 0.2952\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 2.1399 - accuracy: 0.2989 - val_loss: 2.1120 - val_accuracy: 0.3118\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 2.1131 - accuracy: 0.3150 - val_loss: 2.0890 - val_accuracy: 0.3274\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 2.0902 - accuracy: 0.3271 - val_loss: 2.0691 - val_accuracy: 0.3377\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 2.0706 - accuracy: 0.3363 - val_loss: 2.0492 - val_accuracy: 0.3414\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 2.0509 - accuracy: 0.3414 - val_loss: 2.0257 - val_accuracy: 0.3483\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 2.0276 - accuracy: 0.3474 - val_loss: 1.9973 - val_accuracy: 0.3569\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 1.9993 - accuracy: 0.3556 - val_loss: 1.9659 - val_accuracy: 0.3655\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 1.9680 - accuracy: 0.3641 - val_loss: 1.9347 - val_accuracy: 0.3721\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 1.9369 - accuracy: 0.3710 - val_loss: 1.9055 - val_accuracy: 0.3765\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.9079 - accuracy: 0.3763 - val_loss: 1.8781 - val_accuracy: 0.3766\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 1.8805 - accuracy: 0.3772 - val_loss: 1.8505 - val_accuracy: 0.3782\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 461ms/step - loss: 1.8531 - accuracy: 0.3790 - val_loss: 1.8209 - val_accuracy: 0.3812\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 470ms/step - loss: 1.8239 - accuracy: 0.3811 - val_loss: 1.7889 - val_accuracy: 0.3857\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 1.7923 - accuracy: 0.3869 - val_loss: 1.7554 - val_accuracy: 0.3929\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 1.7592 - accuracy: 0.3954 - val_loss: 1.7217 - val_accuracy: 0.4012\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 1.7260 - accuracy: 0.4025 - val_loss: 1.6894 - val_accuracy: 0.4072\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 1.6939 - accuracy: 0.4098 - val_loss: 1.6586 - val_accuracy: 0.4125\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 1.6634 - accuracy: 0.4139 - val_loss: 1.6286 - val_accuracy: 0.4162\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 1.6338 - accuracy: 0.4178 - val_loss: 1.5987 - val_accuracy: 0.4211\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 1.6042 - accuracy: 0.4212 - val_loss: 1.5686 - val_accuracy: 0.4250\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 1.5744 - accuracy: 0.4268 - val_loss: 1.5385 - val_accuracy: 0.4340\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 1.5446 - accuracy: 0.4334 - val_loss: 1.5088 - val_accuracy: 0.4407\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 1.5153 - accuracy: 0.4404 - val_loss: 1.4794 - val_accuracy: 0.4518\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 1.4864 - accuracy: 0.4516 - val_loss: 1.4499 - val_accuracy: 0.4741\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 1.4574 - accuracy: 0.4713 - val_loss: 1.4200 - val_accuracy: 0.5070\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 1.4280 - accuracy: 0.5015 - val_loss: 1.3897 - val_accuracy: 0.5397\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 1.3981 - accuracy: 0.5345 - val_loss: 1.3597 - val_accuracy: 0.5700\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 1.3684 - accuracy: 0.5635 - val_loss: 1.3313 - val_accuracy: 0.5927\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 1.3404 - accuracy: 0.5862 - val_loss: 1.3058 - val_accuracy: 0.6024\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 1.3149 - accuracy: 0.5991 - val_loss: 1.2814 - val_accuracy: 0.6144\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 1.2904 - accuracy: 0.6074 - val_loss: 1.2565 - val_accuracy: 0.6227\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 1.2654 - accuracy: 0.6157 - val_loss: 1.2311 - val_accuracy: 0.6287\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 1.2397 - accuracy: 0.6244 - val_loss: 1.2065 - val_accuracy: 0.6357\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 1.2150 - accuracy: 0.6320 - val_loss: 1.1838 - val_accuracy: 0.6406\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 1.1921 - accuracy: 0.6357 - val_loss: 1.1626 - val_accuracy: 0.6437\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 1.1708 - accuracy: 0.6381 - val_loss: 1.1419 - val_accuracy: 0.6472\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 1.1500 - accuracy: 0.6408 - val_loss: 1.1209 - val_accuracy: 0.6481\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 1.1292 - accuracy: 0.6445 - val_loss: 1.1003 - val_accuracy: 0.6516\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 1.1089 - accuracy: 0.6485 - val_loss: 1.0808 - val_accuracy: 0.6542\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 1.0896 - accuracy: 0.6495 - val_loss: 1.0624 - val_accuracy: 0.6549\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.0716 - accuracy: 0.6508 - val_loss: 1.0449 - val_accuracy: 0.6578\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 1.0543 - accuracy: 0.6530 - val_loss: 1.0280 - val_accuracy: 0.6597\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 1.0376 - accuracy: 0.6569 - val_loss: 1.0120 - val_accuracy: 0.6622\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 1.0217 - accuracy: 0.6598 - val_loss: 0.9970 - val_accuracy: 0.6647\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 1.0067 - accuracy: 0.6626 - val_loss: 0.9826 - val_accuracy: 0.6661\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.9923 - accuracy: 0.6659 - val_loss: 0.9686 - val_accuracy: 0.6681\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.9782 - accuracy: 0.6682 - val_loss: 0.9548 - val_accuracy: 0.6708\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.9645 - accuracy: 0.6699 - val_loss: 0.9417 - val_accuracy: 0.6723\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.9514 - accuracy: 0.6718 - val_loss: 0.9295 - val_accuracy: 0.6749\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.9392 - accuracy: 0.6731 - val_loss: 0.9181 - val_accuracy: 0.6768\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.9278 - accuracy: 0.6747 - val_loss: 0.9071 - val_accuracy: 0.6794\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.9167 - accuracy: 0.6768 - val_loss: 0.8963 - val_accuracy: 0.6816\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.9060 - accuracy: 0.6796 - val_loss: 0.8862 - val_accuracy: 0.6844\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.8959 - accuracy: 0.6817 - val_loss: 0.8770 - val_accuracy: 0.6862\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.8866 - accuracy: 0.6844 - val_loss: 0.8684 - val_accuracy: 0.6886\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.8779 - accuracy: 0.6868 - val_loss: 0.8601 - val_accuracy: 0.6902\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.8696 - accuracy: 0.6891 - val_loss: 0.8522 - val_accuracy: 0.6923\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.8616 - accuracy: 0.6914 - val_loss: 0.8446 - val_accuracy: 0.6947\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.8540 - accuracy: 0.6933 - val_loss: 0.8376 - val_accuracy: 0.6966\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.8469 - accuracy: 0.6948 - val_loss: 0.8309 - val_accuracy: 0.6973\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.8401 - accuracy: 0.6963 - val_loss: 0.8245 - val_accuracy: 0.7005\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.8337 - accuracy: 0.6988 - val_loss: 0.8185 - val_accuracy: 0.7033\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.8276 - accuracy: 0.7011 - val_loss: 0.8129 - val_accuracy: 0.7052\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.8218 - accuracy: 0.7031 - val_loss: 0.8074 - val_accuracy: 0.7063\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.8162 - accuracy: 0.7046 - val_loss: 0.8021 - val_accuracy: 0.7078\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.8109 - accuracy: 0.7064 - val_loss: 0.7971 - val_accuracy: 0.7082\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.8057 - accuracy: 0.7080 - val_loss: 0.7923 - val_accuracy: 0.7100\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.8009 - accuracy: 0.7096 - val_loss: 0.7877 - val_accuracy: 0.7113\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.7962 - accuracy: 0.7109 - val_loss: 0.7832 - val_accuracy: 0.7135\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.7916 - accuracy: 0.7126 - val_loss: 0.7789 - val_accuracy: 0.7156\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.7872 - accuracy: 0.7137 - val_loss: 0.7748 - val_accuracy: 0.7169\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.7830 - accuracy: 0.7150 - val_loss: 0.7709 - val_accuracy: 0.7178\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.7789 - accuracy: 0.7163 - val_loss: 0.7671 - val_accuracy: 0.7188\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.7750 - accuracy: 0.7171 - val_loss: 0.7635 - val_accuracy: 0.7200\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.7711 - accuracy: 0.7184 - val_loss: 0.7600 - val_accuracy: 0.7212\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.7675 - accuracy: 0.7198 - val_loss: 0.7566 - val_accuracy: 0.7233\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7639 - accuracy: 0.7211 - val_loss: 0.7533 - val_accuracy: 0.7250\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.7604 - accuracy: 0.7226 - val_loss: 0.7500 - val_accuracy: 0.7261\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.7570 - accuracy: 0.7241 - val_loss: 0.7469 - val_accuracy: 0.7281\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7536 - accuracy: 0.7256 - val_loss: 0.7438 - val_accuracy: 0.7300\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.7504 - accuracy: 0.7276 - val_loss: 0.7407 - val_accuracy: 0.7318\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.7472 - accuracy: 0.7293 - val_loss: 0.7378 - val_accuracy: 0.7327\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.7442 - accuracy: 0.7307 - val_loss: 0.7349 - val_accuracy: 0.7342\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.7412 - accuracy: 0.7324 - val_loss: 0.7322 - val_accuracy: 0.7360\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7382 - accuracy: 0.7336 - val_loss: 0.7294 - val_accuracy: 0.7370\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.7353 - accuracy: 0.7349 - val_loss: 0.7268 - val_accuracy: 0.7383\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.7325 - accuracy: 0.7362 - val_loss: 0.7242 - val_accuracy: 0.7400\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7298 - accuracy: 0.7374 - val_loss: 0.7217 - val_accuracy: 0.7415\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.7271 - accuracy: 0.7387 - val_loss: 0.7192 - val_accuracy: 0.7427\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.7244 - accuracy: 0.7398 - val_loss: 0.7167 - val_accuracy: 0.7435\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.7218 - accuracy: 0.7414 - val_loss: 0.7143 - val_accuracy: 0.7451\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7193 - accuracy: 0.7426 - val_loss: 0.7119 - val_accuracy: 0.7459\n",
            "313/313 [==============================] - 0s 874us/step - loss: 0.7372 - accuracy: 0.7317\n",
            "Test loss: 0.7371663451194763\n",
            "Test accuracy: 0.7317000031471252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAABvCAYAAAA0RRMsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9a5Ak2XXf9zv3ZmZlPfs50/Oe2dldLHYXIEAsIEAECEHmQxTDNBVimKQsW1ToQYUjFH7IssUPdlC26RDD/kCFpJAVtCTrGZYp2RGUKFGUCT4EUiIIgAQIAljse3dmdqanX9VdXVVZmXnv8YebVV3dO7M7Pd2z07Osf0RHddcjK/P0zXte/3OOqCozzDDDDDPMMMO7C/OwT2CGGWaYYYYZfi9ipoBnmGGGGWaY4SFgpoBnmGGGGWaY4SFgpoBnmGGGGWaY4SFgpoBnmGGGGWaY4SFgpoBnmGGGGWaY4SHgPaOAReRXROTPvNuffVQxk9fhMZPZ4TCT1+Exk9nh8KjL68QpYBF5TUS+82Gfx90gIjUR+SkReVNEtkTkb4pI/BDP50TLC0BE/msRuSUiOyLyd0Wk9pDPZyazw53LiZaXiPywiHxTRLZF5LaI/H0R6TzkczrRMoPZGjsMRORHRORLlayui8j/KiLRUY974hTwI4AfAz4KfAB4H/AR4L9/qGd0giEif4ggs+8ALgNXgf/xoZ7UCcdMZofGrwOfVNU5gqwi4Cce7imdbMzW2KHRAP4rYBn4OEFuf/GoB31kFLCILIjIz4nIWuV5/pyIXDjwtsdF5DcrK+VnRWRx6vOfEJF/JyJdEfmKiHzmPk/l+4C/pqqbqroG/DXgT93nsR4YTpC8fgT4O6r6NVXdAv5n4E/e57EeKGYyOxxOirxU9Zqqrk895YAn7udYDxonRWbM1tihoKr/u6p+TlVzVb0B/GPgk/d/ZQGPjAImnOv/SbDWLgFD4G8ceM+fICjDs0BJUI6IyHngXxKs4kWC5fL/iMipg18iIpeqf9altzkXOfD7BRGZu5+LeoA4KfJ6FvjK1N9fAVZEZOk+r+tBYiazw+GkyAsR+ZSIbAM94AeAv3q0S3tgOCkym62xKdzjvj+NTwNfO/TVHISqnqgf4DXgO+/hfR8Gtqb+/hXgJ6f+fgbIAQv8JeAfHvj8LwA/MvXZP3OP5/cThJDXKeAM8HlAgbMzed3xe18Gvmfq77iS15XZGns0ZHbS5XXgGOeBvwy872Gtr0dBZrM1dqQ19qeA68DyUa/7yEnkdwsi0gB+CvgeYKF6ui0iVlVd9fe1qY+8TlhUywTr6T8Wke+bej0Gfvk+TuV/AeaBLwMj4P8AvhVYvY9jPTCcIHntAtOEmPHvvfs41gPFTGaHwwmS1wSqekNE/jXwTwj8jBOFEySz2Rq7v/P5I8BfIRgL6+/0/nfCoxSC/m+Ap4CPq2qHEAKA/eHgi1O/XwIKYJ3wD/qHqjo/9dNU1Z887Emo6lBV/7yqnlfVq8AG8CVV9fdzUQ8QJ0JehDDNh6b+/hCwqqob93GsB42ZzA6HkyKvg4iAx4/hOA8CJ0VmszV2SIjI9xAcru9T1a/ezzEO4qQq4FhE0qmfCGgT4v/dKsn+43f43H8qIs9UVtP/BPyzykr6R8D3icgfEhFbHfMzd0jmvyNE5LyInJOATwD/w13O5d3EiZUX8A+AP119zzyBMf737ucijxkzmR0OJ1ZeIvLHx7k7EblMiFJ99j6v8zhxYmXGbI0dCiLyHxCIVz+gqr9531d4EA8yrn8/P4RcgB74+QngHCFmvwu8APy56rVoKp7/V4DfBHaAf8FUjJ5AHf9VYBNYIyTnLx3MBRAsqN3xa3c4v09X5zgAvgn88Zm87i6v6j1/gRCi3yEQKmozmT06Mjvp8iIo3OtAv3r8aWBptsZma+wY19gvEwheu1M/P3/U65bq4DPMMMMMM8www7uIkxqCnmGGGWaYYYb3NGYKeIYZZphhhhkeAo6kgEXkeyT0YH1JRH7suE7qvYyZzA6HmbwOj5nMDoeZvA6PmcyOB/edAxYRS0iKfxeB+PAF4I+p6teP7/TeW5jJ7HCYyevwmMnscJjJ6/CYyez4cBQP+PcBL6nqK6qaEwrfv/94Tus9i5nMDoeZvA6PmcwOh5m8Do+ZzI4JR+mEdZ79HUiuEyjfd0UiNU1pHuErH3nsAP906u+3ldmDkpdYC0mMTwz5otJICgZZghkJUoLNFbSqdNfwO4CPJfxEQMMhgC8NeCHeBdsbgXrUHVtPkkPJC45fZmINWIsmEXk72KtJzyO5A1fe87WKtWiaoEbwiaAGooGHQQbsyfgY8FDWmCQxWIurGVwiaAymXmJEcd6gKsjAYDMwpUeyAoygSYRaoWgIGitR4ugkGYrgVCi8ZdivYQqI+x52h0c+1wN46GvsuCDGQFRt6UXBA6xweaj72OSejCyuYfEWaDnqcUHpDV6F0lm0NHsFTQAmbGpR7GjGObm3DPMYCkNtyyPDUZDZMcutx9a6qr6l/zQcTQHfE0TkR4EfBUhp8HH5jgf9lScWv6j/7B1blx2rvIxFjCBRBNYGxRtHSLtFfnGJwZmEtR8Y8tGL1/iNlx6j9kpKsg2tNz2mVMQp4giPCsNly/CUIVtWas92ia1ja7OFDiJO/YZl+QsbYRHvDsA7KMpQ75bnaFGC+kMt7nuRFzzYNWbnFmBpnuzKIm9+exiXeubzBfXrPcx2H93e2f8BX12fkX1Py8I8w8eXKZuWwSmLS4Tl3xkQ/84raJ7js+xYzvddWWMiSBSDEUytBnEEK8u4TsrupQY7lw3ZktJ5doN6XLKT1RiNYsw3Wsy96Em3HI3XttHYMjzfomhZ1j8o5GcLVs51+QNnX8Kr0C0arGZtvvbbV0hXDad/K6f+xVfAuWD4OIcfDo+0YT7MNWYajWC4yFQgUj14xQ8ztCze/tokrDFTryP1FKnX8Uuho6RZ30b7/XCc0ejI5zqNd20fEwExmMq4E2vDY6eFbzcpTjXYfH+N0YKQfHyTp5dX2SlShmXM2m6T3noTSoO4ICdNHRJ7zp7u8olTr/H6YJEvX7uA36hx5WdL6t9cRbMRFDl4RZ0LaywvDr13TeMX9Z+9frfXjqKAb7C/BdiF6rl9UNWfJhTG05HF3+tFxznvILPjkpdJU+TCWbSZsvPUHINlw3AFRudzJFKiWkkt7fG9l17gyfoq5z/Y5eaTc5RqyJ0FoNTw6FXwKqwkGYvJgEgcsTgchvWlFpmL2H5fna0fThiMGvQHC7hBRHo9IdqF5a/m1F/rwuY2bm3tWOUFD2aNSa2GRBH+yjl2nmrTu2RoP7dOM8m5/uQ8rt9GBvNEwwshWuAJj9XN7mNFDWBAreLqntryEFWhWKtj+wbj6rTbT1G/2Ud+9wW0LI/j1B/4GotWTlM8fpbRYsLahyKKlqJRuF7fdNh2RpKU1OOSyHhOtfrQAvdtO/jfL5QqbKmg6hkVPUSUx9s9ltNdasYxdDFDl7CV1ym9oXVlm+xszOvvj9A/+jjRdkT9llBfV5Z+4WXc6u0HKi84/jVmGg3Wf+hDdJ+u1kqi4MBmhmhXuPDLQ5JXb+O3d/C9O7RnFsHOdZA0ZeM7HmP10w4ST1wvUG8ouxewA8P5X/E0ful30aJEi/yopz3GA19jEieYVhOW5tn62AqjeWFwFvI5RWMPiUciJWnskiQlTy6tsVzb5UOd66zE2+QaMXoyxiEU1T5mUYz4yWMrGpGdi9lZSnntTyygg3OYzGBGQtwTGqtKreuZ/8JNdLMbjJnjkyFwNAX8BeBJEXmMIPwfBv6TYzmr9y76vFsyi2P8QovRYo3uE4bBpZKLj63xpy7/OgZPoRFWPIt2l1QKnktfI5WSRVtw3jawcnd6wM1yl18dXqTva7hGeN8n6q/wbJyw4Ye8UqQ8n5/lb7/2KVY3O+zs1Il3W8RFCevrh7Ek3z15HYBYiyQJ+WLK7nlD/7znu8++xPlal8GZhEItb2bzbIwalGrJncWpYVSGW6pTy0htQWpLaqZkMenzbOMGXdfg77zwbeyuNRmsxKARxjVI3kbeh8QDl5m2GvTPp+yeNaS/b4NnFjbYLWoU3hIbR2IdpTcMyxgjylwyJLUlv3/+FT5Sf5UzdsCVqMGujvjiqEXXNSnUkqvler7E69kiQxczKBO8Co8tbJLYksuNTS7VNvn33at8/tUrZNdSlv5d86hjUB7KGpMkpvs0fOyTz7OYDDiV9Nh1NW4M53mpu8zui0ssbLaQLLvzeAQxSJqi7Sbdp4S/+O3/mnk7oG2GFBrx24PL3Mjm+e03Pkjz12KA41QeD1xmEkdIo0652KL7PkO2UnL5idt8eOk6NVPSMDmFWrpFA4C6zYnF8VR6kw8lt2gbYcHU9+1jIy0o1PFKCS/mp7F4nmrXKFqWT6+8RCyO1bzDZt7ghY1TbL66QH3V0n6pjRlmSJ6jxXFe5REUsKqWIvLnCeOdLPB3VfXo8xHf+3ggMpMoCqHmJ66w+a0L5G2hf0kpG576+W2uzvV4orNG5sPNOPAhnNr3NSyeWBxWPA0z4rTtEUtJUwqMKJnaiRXpMHTdaW6VcxRq8RoW+NdHZ9l022S6yI5PyXzMU/O3WawP+N1PnaP7/pT67XM0b5yluVpQ+/Vv4Pv9hyavd4IWJXiPGTnsCNI1w//7lY+QNHOeu3CNK40NTiU9Vmo7xOJo2BF2KpHrql7xXg1ODQOf8OvbT3Jz2KH/Rof6miHuVZ6zP/bA0AORmWk2kVaT0aVFtp4y5B3FDmu8rMt77zEeaxRVIS/DmtmJUqzxGFE2yyZtm7EY7ZL5mOt5ULbjtbSeN1kbtiicZVjEeA3RfBHlxu4cXzCX2clqiFHKjmf9U2eov/8Ura/epHz92t1O/Z3wcNaYQGQczWjESrzNcmw4nexwOu3xL763xe3ft0C0u0g0EJIeNG57XAK75w2uBq6u+Fg59extzkTbWAmGdaYxDZPTjkJaQ7PRcUVXpvFA11j+9AVufSIl7yju0pBmIyeNCraLOqa6zzxCv0z2fX4tb/O56H20ohELUR+L4hC8GjIfM9KI3bJGt2jgEUYuwogydAlxFX0xKAuNIdn5mOFcjWs6R7Izx9wrBemtAXatS3n9LUGS+8KRcsCq+q+Af3UsZ/J7BA9KZpIkSD2l+4F5sh/ocn5um+889TzL0Q5JFTLu+ZSeq5NpxK5LKbxl5CMcpgozGyIT3lszJWeTLhbPtmsw8AlOw/sgKOJpbJaBZJGagoYJ1ujH517B4vmhM1/A4vn/tp7lN29eovv1OZ74ndY9KeCHtca0CNauzUpspjRuQet6TN5JePG7T3E23eZKusHlZI3TtsfVOCNGaJlg2Nx0Q7o+oucTur7BVwaX+dLqBbrdJp2XDM3VsJm6WIISPs5zf0AyM/Nz+KUOO5cTymf6xJEn203IewkSe0ykIIpQ8V5UAofPhzUzyGNuNOfCsUTxKmiV3vAqKDAYJQxHcXjeha1WvYSfoUVGBk09cTuHhRFrn4wxfcvV3jLmPhXwQ9vHRLGizNkhF5MNUiloSo5pev7st38Og7LpU7q+wb/c+jC/8PzT1Js5/90zv8CztTeJq3BqoYYcw8DXuFEukPmYhh3RqRTwcfELpvGg19jt51L+8A/+e+aiIa8Plxi6mMxFbI0a5N7ivMEjlBXBb+QspbP0s4Q8j7DWU6sV1bmGdVYUFvWCGA2vxyWLzcEkamNQElsSied8s8vV9galGrYea7Cdp7z5+XN0Xu6w8HyE3HjzWMhaj8w84GNFRU4yjQbSbqGjEW6zG4hDd4LIsTPjjhUicPUS/cc6dB83XJnb5mw9kIMyTSiqSYmZxmQaUfiIwlsc5i2K1Kvgq7zJdtkgNiUDn0zeP1bAd0PhLYWEcGwsDiMe5w2JhDDsxfku31hooXNtTH+A7w/uLvcTAjXBUzWlYjNYX2vz7+xjjJZj5myfRBwbbkQqnoKw2W26mB2tca1Y4vXRMl/eucDWrQ52O0IcuARUgvKV4/eAjx8i+FPz9B5vky0FhUnFgOfAmpBKCXtAkEoZQ55HbJsU1bBxjt8Le5tkWRrK0gbl7cPz+KDI0eq7nFDmFgSk5vAK2VJC58J5dHcX191+NyVz3xAXPLiRhm3YqaFPQoyjKSWJeBZNRtvk7BQp0Wspg06NVx8/zZlomzNRj4Y4tjUo30zjybEHrsauqx27cfdAIYI7u8jOEy2yU8FAy3w8Ub65jybGmic8uor1rNUaHK89AOeCcvY+vK7VoxGPMYpURqBTQ+4qoxAhEkekBl85HJFx1GxJvuTYzSMa6zXqSVJFyY62d/2eVMAmrSFJjF45T++xNul6TvSlIX4weOubRUIJidcTqyjEWt78jkVq373GM50tPrX4EgBbZZP1ojVRnEYUi8dhGPn9/3ojihGHxU+8k9tFe/K5g7Dc+c4usGyXdYwou66277XTyQ7Pnr3B3xw0GT62QD2ymDfevDPJ5IRAjVBF3xEHya7S+XKNncYKv/RcnfknBqxGc3TjBrE4mmaEwfNmuUDXNfitnUt8bf0MmzfnWPp8RJQpRRNGc4ZooEQjRcqTv0uKtWx+cI7bn3RgCsgiHAQFDKFmTRRjPFHkQ9nR2HP1BvWGfJCQDxK0MMjIgASCGqJ7SlwUbLXexs/56ncPWEUKQbYSfOKpnx4gTaX7xBwqF2i/3IOv7JxsgxnAK3YEtwdtzqQ7ODVkmtDzKQaPjzdpm4wVm3PKxnxj4zSP/6M18nMd/vnVDzC4kPDp9vO8P15nR4PnC+G+tOLZKJrcyjqY/ITLYQpiLWvPten9wT7z7SFreYvSW9ayFqMyIrZusjeNla6rfoegfCPrkbTAe6EsLargqlSIGA17oPXUkwJr/KRErpzKFYe9UDEEJZ3Y4CG/731vkj9hWc/Oc/Hft9DB8Mgs/Pe2Aj7guY7LcczCPNpIyRfrjDoGU8TEzWbwBX3YDLUsH0Te5NghcYKppxQd+MjSLZaT3QlBwamhmMrfxjishJu0YQIhIzb7jQozlcecVtLTStiK3/c+CPmYcYg65PMEj933nlgci3aXuTSjP2+JduvEt2IeGVT6IO4rphS6W3V+d/scnWTIetomNQUtGzzgW6M5ukWDl7eX2dpsYbcj4oFic6VoVkp9Eqt9RFAp2cmjyt6jF9QJiqlGrTHxOHTswfrwPlz1MzlWUNYoE2NnHzS8JtXjWBnLO0RjTjqkFAZFvO8+yzXC4smr+9YCNYkpnIWNDeI0ZneQspk3KTSaxK8yH2MlKF/gnqJVJwrGIlFE0RROz+9WdboRpTeT2l7nDZhwfcFbBTtOeYgiKiSRo3SKq8oAvRfUKApYGzzfJHLUolCjPuYmHMTYyzYopVci45mrDTGi3GqAtFuhfCwbgd6/Y/beVcBVDRmE+i2p1bBnTqPNOusfXWL3fNgEfQyjhQibXSIaOqRwiFfsjXXKm7dA9e6KePIdU7iTl2yqXeWYHWiJE8xjF3GLTbIzjg+2blCo5Ua+MFGGRpSahPNvmJyGHdE22STn1DYZCXuL0KuQV7e1RSckhjGpaPxcTcLFFNWNvqM1ej5lo2zxRr4cFL9/625aaMSV1ia//LHz1C81uLi2CBubxyuYY4QUHpuFMHTRCAog7iu1HcX+ZsSrX3+cMoWio/gIXNOBgbhrsYPQoGRxRzElIFDWQzMTNeGYPCJ7pDrH3IsD1DTYvSC4D+5ijDIaxKgzaGZRb/GR4mom5H3d2IOtFKevvGKraLOslG91/NwgpYQyLncHoYw/74KS9nUPAtluDc0NF150dH7zGtrbPfneL2EOe9KD9Y02a+0WiTj8mIuBZaA1rHoK9jcekdKTb9d4cfsUbsGwYhM2fT4xslNbYNQzFw3pRemdDZqTBmOxC3NIq0nRgQvtLqU3ExZ8ZPaics4bYhtCwrDnGIwdglL3lPX496Iqq6zHBVY8rXhEOw610a4yUkpv930+9xHDMjgHIxdReCW1BXVbkK2UbH7iLI3VguQ3+neOnN4j3rsKGBAjE+NErEUbKeVcnf45YXC5DDd8IYg3ZMsxUWYxeWhAUe/W9xTnO4SeZarpguqBfLE8uB1WrMF36uTzNbRRshztsOlarBctvAo1U+4LFVsJbOfUFCyZPqmUzJmCWAKV0YqQq1JUpz9+vgCcjo8R+pem1XUVWuKA2HsSHIWNiCvl7OStVrhDmI8HcGbEUGtofT+L8aRBVDGuctySvVxwlCnRILxeNC3ZfFCsRTtCBdJNJe57oqESDTw+EfKWwVvZp3geJUSbfdrXIvJOjdx6rPXkNgpGqgeTGzweNWaSq52GeAlGqAWJ/b4IgI59uenORQcQ8uWgkU66GmlmMZkh3RxR3njzQV368cN7TA46iBiUCSao3wknI0Svosl9BwRjXxXJDf083DcNk2AZ4TDEwe/FEvgXkXHoA9x/jhOSJGhaw9WUuXhIv6xNFLCp2vKN9xKDEoknMm5fuHgSnq7yw8FzDooYoBHlJBXrvGWDAh6z7wvde69TgRLyissy+V4J3yuNkuGpFFtE1KKjqdD3rgIWU/0oqEPqKYOr8wxORfQfK7h4ZZ1eVqM/TMiaNbouxhRmsjGml85Q+9bTNG7nxF+/DqMRbre/XxmHuNpeBEJMYCNXi15VQ0eV8piLx8ZflyTsXmyye87SXtiiaXIyzamZcl/udjpkPHA1Xhic4a/f+gyjIibPLd4bXBZBbiDymJoLYcOR3cvxwd7mKIQ8XfUoRqk1cxrpiMtzW/zBpReA8eK2IdRThca8Gs7Xtvi2qy/z1dY5yrn6yZ6JqRpIUtVNqAJlakLuEkLY1EA8CI0oqgg0tgivuUTwsQ0er6083+k98eQ7awGqsL5Jmhe0O2d483oL3yppL/eJrWNT22hZWWeGoCkjwsXmJuRvXdWoJAetiEfixuHlqe8SwAumCL/7mla54vCiRhoaMfQiFn/HUN/0JG9scvITRlNQpbbtSTYsm8NGCB+zd4/0fEqhlkHUZaQFjaTAXzpNMZeG6yeQKnd9Ro6d5H7HnnTPpaFkpzz5C0yshXqKb9UoG8rFdIutojHxRscKtmbLiaI14onFUzPFRPHeCdOh+JopJxUeqSkmKToIKTRgQjYtvWHkQ3pgK6/jVWjasLfOL/TZvpoAlk5ytBTae1YBi5HQM1Q96kHSlN1zEYMVYfn8Np9eeYk3hgvc6M+zWW/Q1Xaw2ONgXQ/OW+zQ0H4l5czNDtLrI8MMPegN7wt3+VCPG0fgq9xEnqPFA7oJ4ojBaUP/vHKx1Sc1OanPJ4trnJc1BAUYiB6Wb3RXGHxpmbgHnW7w5mrbnmS7oGxGZAs1TKnUtkps4YMVLYGtK6UGYlIkqBHKusXHwu75Gv1Tbb76ZIPvOfU1UsknpUljAyCEsw1nom3+6PJvMR8P+Z3mh6m9w2U+VKgGz2vK+HAJ+GjvhreFYkdBUSc+eMUuMfgo9M92CZNuWTq2Nk7+vvgWuI1N2NikudQmXe0wKiPmL2Ys13fZ7jXw/SiUIZlwDxkbcsE+N0gVfhYXPGEtBVEwxVTnMAtaebaiIUcKoHUP1bFQwICJPJILy7+9g3ntJm5n9+EJ5n7gfUhlbBp2h7VJagdClKjva+QS0deITEvqcUF2eoGyacD6wPz2MQN1FBq8YYMnlpJcLUMXs1s8OixoTRNcPUbrjgvJJrG4Sa1u3RZE4uhE2YTfUqglFke7snjHtb6muuBxtytg0qtgXJUxHRUMCtrse28xFbfPfIyRRXIfUbcFNVNwpt0juxAz7LUDr+gIeM8qYPUKZRkeASLLaE4YLXqeaO9wqbYxifUD9Ds1ysKi/QgpDBgoW47hmYiNj58mHngat85gsgLTy5C8QIcZuttH0hoy10HThGKpiatb4p0c2xthdgewuha84WMux5M4ZnhKKC9knG0EJiVU+RDx+DH5ShyxKScWXXdQp/W6km770DjfQNkw+CTBZp7W9REaCaP5mNyGoQEm9yH+HANGJqFU8UH5NG9CuiGstVJGH4pJbBkUr2j4/iosnfmYphlxyu5wJtnhi21LY2kR7Q8eSL3iceCgxypTHptKYEr7mL2WlISBFWpkT+HeDRUJ6VGC3dxl4YUmvQuW+MOOc/UdXqyfYjcN95K6QLbyXkPdpZNJumfM+RsHUqiMG4OELkMmkGbEBwWNBEU8tlc0UiQXpJeSrgtmdxT69+ojomkqqCo280QDwzCPyNXu41nE4kikZOBrrLqcZ+dv8fPfdRZNlCeu3uJSc4vUFNxylp6vV1GmPatu6BKGZYyczMKNfRBrKOfqjJYSJC0xBM92MQl9Amom7CUtmxGLo1DLyMc4NawWHUpv2CyaE6NjWMZ7pC2gqB7Hf+vUDS0VEWshHdKIci43NrmYbk4UcaG2UrwlnSgLRMt4RBQ5ymPIr79nFTDe7bsntZYwPOOJL/R5bv4Nnktfo2OG1EzJ6VqTSDybwwZba4vE24bRiiNeGOEWRmy+TyiziPSNBlEfmjfb1LqedD0jurmFn2+x82SHvGnoXRbKptK8kdC8Wae+1qQ2ygOR67j1S1pj+PiIP/z013mifptCIzyG2JQUPpoo5NAcYxTqf9Wyvd3g/b+2Cptdsm99jGw5ZjQnFE3D3KtK9OWXMIvzdL/rAnlHaN4Sat1qGlIUFK8aQbwS9xxR5mg+v4V/8xZF81vpfVdKw4ww6KQxR80UeDVsuwZNM+JqNGCtfoN/esowd2EFubUBJ1EBV97/W5TwlDfro9BQ486ff+vvMh64IgRD5kTH4N+K8rVrtG7cpP6xp4n/SMm3tK7xYucUrxeWPIvRQaWIK49VRoIpBZPvebxAtY4qEk0uE5mqCS6whnJgTB4Y1r7mIVaiHUvnZUg3HWxu32tHtZMFr8S9glrXsjWMKLChPSwhN55ICJduuBZ9TfjBpc/zX/zALwEw8BE5hjXX5uujs+RahaAJjTk8hu0iZSdLA/nvhEOShGylxu5ZS6MV6uoX7S5xGqyHsfGeSFDOAx8iBptlk2uDBXbLGq9uLpINE8qdhGjHIm5vTUlZcTcKMNXv4qq1FoWI1u0zHvT4rtAAACAASURBVN9y7D5e42K6SaGWnksBWIgGWPEsRH2aZsSbtXkaScEw4sjG83tXAVcYN/V28w1cy7PYzGjYEQ6ZtBAc+YiFNDDZ1uc6qInQusNYPyFVifW4miJOyFsCGJCUJFqiaMdkC4ayXpWXKBRNGKxYRCHptJCihEPNIbiXixPiesHldIOWzQJbWU24CSvClUcm4ZW4yoEAwYP3Sv9cwu75YDS41GPyiNbFs+SLDXYvCkXHgxjKmlA2hKLFRCGJh9qWIRrGLG6l+CzDlOyVPZlyX3hnzKbO1TJQyNVSplB2UpLNE0rGEtnzZN/pXnu71ysi8ESZ73t8tDxgvENHjmgn44Wbp/k58y2sDxr79yKtSFcVcWriwo6JV3cIwU+XAk/106rCDHvlTyaHdMtT2yrD5JpHFKb0YfRnKRR6563YIWQ+oW0y0srDzYKAQgMJDYp73Es7r8oPIXQ4fRRsO3WOaNeR7Bi6N1v8zPJHSW3JfDIkMSVz0RCD8sZwke0ipZen7BYJwzymt1vHFQbZSjCZUN8VomFQsKYEPBgX5DVRvuP1KEEJhyCowaWGb9qz9PIap+p9nuqsBgfCjgJ5VQoMnsSElICPFczRJPyeV8B25RTD959h50rC+SurfPzUa8zZIWuuTaGWRdunbTIW4j5FO+ID828y9Anf3D7N7V6L4aCG246RwgQCTl0ZnIOhN1V+rw4mkETEKbV1Q7It9C96im8Z0n+tgSmWQkH8K8d7bRpHXFzu8h+1v8K1co5b5RyOoPBiwFiPrxQyhDKkOHFESRkst6V5sj/a5cef+VdkPsZj+CdvfoyXLl2imHP82U9+lmfqN/hb1/4Ar6wu8/5zq3z/6S+TmoJYSnquzmc3n+aN3gIbdoWF3yEYHxqIDHN2+JbWlcELbvLV/Ayvjk6TLStbT6Us787BtevHK6BjgEaGMg05Xx9X4dKiqnM1B5UGb89wlqnSIwnHdLGi9hFRwAea0sgbN7ny04+zuXSZ7U8Y4it7eVjxEkLFPhCtpJKXjzVsisUeqW3iCVdKWyqmtFZ27j6GloGkK8x9/gba6z16ud8x1GN7I9LNCDNMJj3ZYa/JjVOh0MCQ6OUpr+SngZDrtaITQ7fnU7bKJnN2SNPk9H3FHn5ElpUfDEi/+BJprcbciytsrDxG74Kl+7RHG475U7uIKNnnl5h7JYyzbK8N6DhlpcwQVSi2Qw8HY8LeZg0ahd81tsGIHj9GIYUmHkzuEKdEm/3glNRr+FqdV/7gGU790C6P1de5nKzTNCP6vkahEedrW/gF4bW5UzMF/E7Qeo3h6ZhsSbjU6HGmtk0qeShil0BaiKtwDxZW4u0wcCCv0x2mjEzIJyCKrwE67tWh+Lqi9SrJUkr4EYNoGMt2abnLa1s1XPIA7gRjIbI04z5LVlnzBX6qfnccz7MV8cCIhjyZTEVNjOFMu8dztRt0fUJfE662N/jm4jnids4T6S2uRBucrvdYbbS51Njiw+kbpOKIxdPzMavtOWq25CvpChD2ynHuJJUCK3se8XgwQaGWHRcGNri6UrQNvh6dzMockclYwYNe7Fh5vJ03dyfs+2zFjn4kcKDm3feH1F68RXK7xcazy3i/Z42EWybkgicENqrIyVuOy1RSmLsbMKHoAJuD39x6NEPPFdQrFCVm5Ahbj59EiiB4t0h4dJhJ3hOgZopJxzqLn9TcZxLG743riR8laDYC54lWuzQGBWo7DE9FlC3DTq0OwOJNZe6lPmZ7ABtb+w9QcX2klkAUQRRmn08UpDGoHVe5SJjwMf6M88ggQwcD6O5g1FP/YIfVrE3d5rRtRsOMJj3xt4oG3aIOhRy55vw9r4CHVxdZ/e6ChaUen1p8mau126QSPDgAZ0IFXq528lhoxEfnXudiY4temXI7Cy3RSjUUznK9O0c2SNCRRYY2lFh4AauMnh1CmvOxlVs8N/cGf+v1U3S+sRvIWMcE02gg51bIzrVJ/S6vFCmbrkWuUWX5Vqq4Cje3zZBEHF3XYNelOBfqCdnYYv1nnuJ7L/63mCJ4HnYE831AYn7iC38cBGpbSjpUfqPxET7Xfm5PAVkom8F7Of9iCAXaXHm1vwTAhWSLmikmTMOwOYROWT0fbqr4zICeqTP/Yo302CR0fFArk/KhSdOIsREz9TO5D6eVK1PvH9tEBz93sCzpJMO7fXXuWhb4rS5SlqSby3Q3Ukg8plHiCxtaTqpCIXu5SA3rbFxihISez6YMy9XH4JOpTW2smAXs0EDfEu/qkTe+hw4Nm360HaGmzodqNxhoxMDXgqfl37o1j9NHe+VKQkE8YflCaHSTa0SpltIZao+AnGy7zc53PU3/jA3kxSjkbetrim4I5e06olDbcZTNmI2Pr9D94OJefF2BqomLFIFvQLWmpjG+h3X63qvmWGs9DSWVfYsdGKJMGP7sVV7Xq/xKdf/aoWLzsHZtoVy9XeA3DxgCh8R7QwEfzKFNLbpsMeITT36Tp1qrPJPeoG32OsvYqsA7DG2OJvR/i3I5CaGHTGP6rVpg1RHGyv2yeYobdo6eryO9qBopJ/hUubyywdNzq3ygeZ0na7eQ6NPIjVXKraP9o/Zdbq2GX2iRz0XE3rDhm1V4ZI+WN75JjShJ1XzDeCXz8WQ6jd/ts/K5DZY7aegAVnpcMyGfT7AjT/rKOjoYViKWQCRzlZVuBElTBh84R96x1G72cIA4ZXtUZzNucjbpTs5nzPAcl0WNz3Wx02fdGcrGSVS/FQ6SsKYwVq7Tynn6tcnn2aeTJ17wI6N8x5je0FXxgwEGiPpKtGspO2BbwRhTY6cGTsgk9xtKkaoN0Vc8tzJsmD4Cbyud66aCCwJSCDYPRt64ZeyjDB3lyCADgYuRoetzvlbdt0XFih6nj0zF6ZguoRnvWW5KAY97I5e+aihx8vUv1FO6T1j6j1UaU6F2O2L+RQ11zArilWjo8Ylh53HPX/jUv5lEAgq1rJdtBi7h5miOrVGDfpmwnaU4L5QuSHF6YANAbB2ddEQ7GfHtSy9yLu7y5f4lXu0v8VtfeZwLvzgi2s2RwQgpHbrTQwdDtCgns5WPugrfUQGLyN8F/kPgtqp+oHpuEfi/gSvAa8APqurxaZjD4m2sPONgp0jZKhv0fY1YyspKtNWYvv1mUtOMgNHkPeEg1cKuOsw8O3eTlXqPtfkWG6cbk5Fqjbjg06de4rN/+Tf4B7/Spb5Qo/lfxqCeQnMIQ6xf5KgyW5rn9kdb9M/BhztrNCWnL3vVtL4KX4UQcOiuk/mYkQ9zV23kKM4tEiUxxVKTshFyIxhwNUNRF0xpQZdDjqQSrziPFG5CTPKJZTQfUdaFweU50sYH2L1guZgO6ETDSdgsllD4Pp7WYlFSKfA247HOJq//1M/xxV99nZoafr98N8DxyusIUJE9JVuyr/xo4sUeIB+99SBTaczKEzZTx7offE2/yDo3SaidGJmpAFZJEsfIm0nnVbXgNfTPHkdZxzpj/Ldxe4p574BTRosGzyMaCHbkQ1nfIXDi5KUaQp7eYfJzk6dtFVaOxTFu8TCuXT3YszimxFRVD7FGxKYkEUcmyrCMGY1iWkcoQ3rXZJYXNG4paiPyOaVsO8qWZ/uqwcdKsehRqzTeiKltKdEu/NQXvhOJQjc2MUqShN7Ozhu8F5wzlEW1f09Fp8bjAcZjCXv9FBF48fapkGferUE/IuoZbn+0gSkbVXdESPpnsLmSzRlGi0Ljlmfpl17Db+/gs9F9Deu5Fw/47wF/A/gHU8/9GPBZVf1JEfmx6u+/dOhvfxcgTulmdTZrDXo+DeQhXyfzMakpJuHosbJqSphl29cEfC10qNExKSKEUT/Rejn8zR570eJJTcFT8W2e+WMln/3BT/CP/9LXWdw0qPO8xvMAPVV98qgyK0912PpYwcqZLt/SukbbZHR9A2AS6kXDjTkma/S1FkYRqiVJHIPzLZJmRNGJcIlQ1AWXMpn+Ix7yThI2RVeRj8rQ01gleCpqhaIBGgk79YjexTa7lz1n0h06URYUPhEr8TZtO8T6QAqLpaRhRqSm4Fvn3oAfXOZLC3+Im//kb0+u8TjldWRUWmBsjYc/DniwVR7zXpSqOCb5zPvFOS5zkcf5Gl+YPPdQZVYxlInCpBnnggKeDDqKCJ2w/F76YuINjx+r1wX2M6WrRzsKvbWj4eEFd+LkBSGHPRhgcnBTllvo317sm2A2jTGhMXSICjX240Y3Yy95WMQUWXSkTljvlsw0z+m8MSLKEravGlxLcB0HZ0a0W0N++OqXmLMD/vo3PsP2620atwxLPx+jFoq64BMYnhJcXfGxUqXK99beuG3puJtaRQxUhVJDx7XkliHuK81RiLD0Lgq7Hx1irQ9jDb2ggwgphKXHNvjPrnyJv/fNTzD/zWVM6ZCifGuTpnvAOypgVf23InLlwNPfD3ym+v3vA7/CCVXACEQmtC0z7E0LgYplSCAM9ahPnh8TIsaDCLzun5vrJ+Fdv8+DNtXzH/9Ewpe+HnKxPlZEhDXeBNio3nokmZnSI31Ld7fOa9ky87YfDAopQq6sClfN2z4WZcO1yHxMUc3TXG71ufnhDnZYw9UVjQI71Sc6YaSKD80Txo0SwmZZeTBTuUufBut03Eg/OjuY5KoMWhkBQZamkmuhEZsueORf7Z1n7bE2NV/fd43HKa+jYuIBH3hu3LFpnwd8F1LW9GcmDTtMqAPWqCKFHAILcoqh7ichPUyZmSLUXbrSTEJ8YwjslX5M5XTHm+HYkJlwvMbNOZxUsg3rMnAUNDSFmZ6hfA/zuk+avCbQYNR51X1q9l5IVOP3TOeAISjowhm0NEfqhPVuyUyShN7FGrvnheEZj5nPw1jL2BFHblKPO98ccut0wm4aM5q3IWKXaGjN2SmxiSOKHLYqH1UVRBQzrjU3oeGkV9kjDBLmBu+2U2RkMCODzYVi3tFshn7Ro1GE9wZfCLZv2Ow2+dzGkwzWmpjhdiiFu89GMPebA15R1ZvV77eAlfs8zgOHGqER57Tj0MUkWIklhVgyTRh4YeBrrBctRj5iddQh95bHmhtVtywzyV/CXouzscfbNtlESRdEk56ip6NtEusoGwpGyBlBmGsAR5SZ2c1ovtEmG7T41c4TrM53eF9zlcdqt+mYjEW7SyqO+YqF8FujmLWyPWEnf+eZ5/noD/88DTN6y7Gnr3f6Wu0BrTJ+T7C4lQ3XpOfrrJVt3hgtUailYUekFcM8lpJEQsOAgSZcyxa5PWrz+W9cJVqPWb61uu/4xymvI2EcZp56Ss2BkDJTxI7xZw5gmphlqg77ZUNCHXT9eKo131WZjXkXGvKxSd9T61rKjgmemfGT8Lw4KgNt7+M+qmQ4GbAAfkxYLWTSOGGsW9QoURbqf+PdYm/DM7YauuIOTcw6KWtMvNBTT3YPSnfc23hMbIS9qgOHTByMUREjmcUccxvcByEz6bS4/cmSj3/gZSIJRvpOXmd10MKK8vWdMyTW8czCKs8tX+OZxpt8pP7avvadY2QakRMGLORTnBiP2euTMOUQpFUeuSmhp/Stss2a6/BStsKXupfoFwlr0iTLYmzX0FgVyo06L75wleXrCrfWcNv3P3/6yCQsVVU5aPJOQUR+FPhRgJTGUb/ucKhKSNKqldgY0xajq/4xA59MWpllLmKY7jXZnjSWEIdD9hW3uwO7bV8jXGVdGRSNFUn3E4zeTmb3Ii8ZFdS2Qk/mm6vzDPOYjbkmN1tzzEVDzsZd2jbjyeQWCT7MCq0WqlehYXKeijdoG6FQxVH1yq/OqKjIH4a97pNW9l93US04W23EbdOl6wPT+3q+iFdh4GoMqHE9X2DkI4YurqacxNwetNkepsS3Y9J1IerfvWXPQ1lj41GTd2mScSev+J2PyR4RSfdCsWokkNyOes7T53fENXbI78IUihkx6d8cvog9JVwx1WTq+qebIVBFVoD9zRKm8ndUk6hkakSQHFOx68Pex5zujcabPIdhL5N+l88dIGFNnnfVAIwHSMI61jUWKe1oRGxCON2rYVgNOugXNQbleOJRMDDaEmyA8TjUvDJIMo0nXJODshmT1qxq1Z/e472pUpDlpGd+SEu6SQqgk46IrWM7beJqVS/4JIS6JY7DJKc8vy8lfL8KeFVEzqrqTRE5C9y+2xtV9aeBnwboyOKDWQ7jzVL9RAgSJ0gSkzeFx1vrE292x6f0fY1M4+DFSsGIOMx/dDH9MmFYxNRMyZlom55Pyco2wOQfM7aacrVsli1SUzBvBzg1fH7wBAOfsF5kYbG0S/KnzpFsdihHG3E43bvL7F7k5W/dZuWziqYJ5b9t4GtNtlpz3G4+RtEUsiUhn1M6H97gYmeLj8xf41KyTs+ljHzEzXyOXxo8gRXPZtli4JN9/ZqnG5qPYe4Syxp/ZtelDPx4RFrOtqvzpe4lbvdb9H/5NEtfKyZsRlFIC0+9VKLtLSQrGN6+ue+4CTVKineU173K7LAwjQaSJIxSO/F4VSSU1Yy/V6a837tgn6KZ5JLDc2rA1ZSyJki9jjgfJmfdpzV9rzI7dnl5JdkpqK8bhmf2wn5qFSJwKXgnxA4kq+waP77+4N3aTCZKd9wqcMyKBvaUs+O+5XMQD3uNjSFaVTLeQyW8xeOr6UeeOyjeqs6+LCxmJIg7Qgz6DngQa0yzEY2XE35RnmblTJf3LdxmMenzoc41bucdfvXmE/QGKd/snkOGhn/Tepa/PvcZijyi6CWhBHTCFK1+jCK2svQqA3DSA7oiYYXOSgfCW1ZDk0PrMbFnrj3gzz3xa5yPN/n7C5/km+un+cDybf7A4gv8nZe+jcHrl6hfm0ffeBPf6x1anvergP858CPAT1aPP3ufxzleiGE8G1DiCKmn+CT08py3g+DtVgvUj0MR4zaJGsLIY/q+EaVpRhNrCqgGC5RVONWRu1AzbFQnszxXiw6bRRNxoe+kSRx5J2HpzDMMXv/cUnWoI8nMDwb4V18P10mY2Ru320ijDvMd8nMd+mcSbi3PMzwdc6m5xfvSm1gJJKihS7hZzANwazTH0MVEJjTXiIx7C+njICZDsKcIIuMIQifKOJ3sgIONYYPN7Sbnfreg9vNfuOOxxt/kDuSaTnGO13nhWOR1aIiE9VNLQpOM6Xv0QI73vsqIxjlgxh4wYA1iDXqE3r0PU2Zm5IgynXjAMp5YYarxgUKQqwY7eS8CoG9t86l7P9N238SYOSYF/FDX2D3CV8nx6XtyevzewfzvGKqyN9DiGPFAZOYcyQ6MNmJ2Oin5XETNlFxO1gHIiojRICbaiEh2hLJhyLYjzEhobk3xUsbcFBPuKx+POS3sW1+hbDRwDEzOntGn4GLQGMqGUs6V5PWIb6ld4+kk58WFl0ltwXcufJ0fat/km+fO8MW550i6Nex9TkW6lzKk/4tAuFoWkevAjxMU78+IyJ8GXgd+8L6+/RghNoSJdZwbunqJ/pUOvcfgmfoNFu0umxUZKTUFsbqJ8o2rUVexeHxDyL2lbbOJ8k0ropVXISMhUYcjTB9pmBFtO+R81GXNtfm124/z2z/+C4yef4Vye8jGf/6/YS9/FxevfoZrr3+uU9H3j11moZOMQ8qS2ign6rYpWh2Gy3M8P7/CZzrPB1JY1aijZkIIpxmNqr/LvfnBb6OAp29+I2HYgqnGDOY+Cv21TR487dV5zFpC3Hv7IQtf1c+zxRoFIz6n/5KrPMNlnuJ1Xnhg8npbqKJFCbZASmXMs5OKMHPnz9zl6SkvWUWQcdJYQumNzYRo5NFRjs/v3fs9UTJTj1R9jU0pEwLM3ut7Fsy4vaQfGx7V5mdzsMPgEbtqw/TxlIECk+b599P+70TJ6w642xWNjdxxyBQIQhATSI1TmmWav1FLc4bNBH+3ISH3gHdLZhJFjObAn8pJk4JBmbCZN3l1dJqXBqfp3WwTbVt8TRme9TBXMD/fp/SGbJgEY8P4EAgVnTzGZipVccASCWsUfEU88L7621l8KbAbU7sV0y/a/OLjz3Krfp2v9C7y8vYymfsQzw/P8QsvP82lGxnR6jZ+9FY+zb3gXljQf+wuL33HfX3jg8J0LkgM2fkWm++P0PNDrkQbNExJz6fkYkkpcGImtb1GPA2bV8OaQ+emhslDq0SVapKPVB50GCIwTcTqmIxTNqevI66vz7Py/X+S8s/lLCz16L64yMqveuxIAV5Q1Y8+iMvXIg/F4YMBbGxi1posmytkKw3e/Hhn7+atMCZPNUwe6g6r3Auwr6EHMDFUxq8je+Gymglh+YFPKtZzaFpeeotsJNRXDbZfvG0q6oPy8btc1IOT1zvCudAq0PnJCL1Do/KWD3rJEwa1o+qsoyGHdIgyhpMmMyk9pgizk/0BBTw9vnHCoK+8lOqcQ3ehkVb15ZWMbBWCnlLAvupMdli1ctLkte8UJHAtzDsYX+Nxgx4fmNNV20lbGdYhuhe29DQpGNQdPr7/mXnvmsyspWgrrfkB9aRgVEb0bI2b+Rw3BnPU1izxjtC/4omWMs4s7vAti29WDkVYHAcjd2OyGuxFCcZptGlHIzJ7XcW8CteGC6wNW7x27RT1NYspLb/VvcjAJby8vczGTpNuv843zAr+1SbxrVv42+uhDvg+8Oh3whrnf9140GigVkb9klo3ZrcfkWlErJ6YoBx8Ve8wrutNJdQDjztdeTU0psLPwQKFmOA1N00+ac6de0umMbdcja5rcGZxh1sqaG7YvDlHc9VQv9nHjB7wXLA75MGDPAIhY1C1tzOilRdruFuNwl5Y/t49DVuxF8dK2iOYItTYifdTIdx3Lhk5KRg3e5gMXDji8Sb544M1xO8FqIKGaMFglJDnNuTmHJM5wGMWtPhQmqnV7OTJIar6c5uF310yZlCH9z0qw+WPC5PhDOMSyirNNQ1T3XexCXvTmMjVruX0GjkufpeJr/cDCTW8S80BzTinEeUs1/qcTbZ5M57D5NWEo0Lwfuw4CYWPJvPcjdN90TnYcxIOktvGhkw0ifx5SrU4FSLxzCUZYj3iwvS7xDpadsR8OqSfxySRI41KXm+30VYdaTWr6XIPphHHycXUdBYt9yu4eGtI60bM9lZE1zeqAddVL9WpGl+nJpCoTAiTDnxg0d0q59hwrYmXu0dZV5bsLg0TRhr2fErXNdhxKYVGfO+5r7G9UudnfvujdL4RM/dKifnaK+h9higOIwesBef2yUIUisKyVnYYVQMo9nrJGjzBs4/fgW35TjDjJgBTOXU7gmioSOkn5xkYOLzVUDhhUNWJathXdnQM8GOn5FGYFXc3HPzfaWgbaEf/f3vvGWNblt33/dbeJ9xQt9LLnbtnepoTSIkUgwRSsCjSlkzBogzItL/Y4wAIToBpGIbpCPiTJRsgYH0SaOsDBRAQDYkAacGGwGASpBikITkzmp7hcHpmOr1+uV6lG07Ye/nD3ufcc+tVva56ocLg/oGHV3VuOnfVPmfttdZ//ReMxxm+NqH1qA7rwFQyT+WH7H6IaPP5ZsSn4TnZTHFZ6GDwhNdqx4F/p8J2FlnjTOZOODKAFWaaLjjiRoCj6bEHuD7cpfaGsj883S/xJLAGXa341Npd8jgy9Xq+w2d6N7lVrvG1ArK9QNSrSsOsSqi8pfCW7XKAj44ToI48HiP6SHTb/NxEwJlxrKThvlx6i1dhlBasZ1PeTm/E4AGGtuRyusdLg20Mymo2ZTObcHNznXKzTz4ZIfvjVp7yJDh/Dvgxus7Hfw9DeWXIzusp9WYVFavCrMwKG1mpHqcmTg4xVHFsX1NDOUr+rXEwTVqjiRJdTAW9kD1k0+8jJrRlmDJsDg5uEJ4pDrORKmZWYwuHqy0Tn1F5217kVUyjN3BqMB0BDR97Cj8uCg5OfE7K6h4XJ6FlpKPbK0bCJJhzDonrcGFW77M87da7xxTtM25DOnWI4JOoomZATGCT0sxblZBe1jpGtDEV7dL4sw2tOKYGXwk+iQzpRGMaWtFEgmO2BolZLPX6zFqRzhKHXWUt2fFA+eiw67JRwmowSgpW8xl3nzwDfXoQQYQFHgrMuzACIz62sUkzyGjxb+6ReYnsAI4SNTnIOg/KYkoiQZesGRASziXMAR4kJf3Y1mqToE2tvbTlIJ0U58MBNxEc0MrhNBeV19CaAYfuug9zbGItH/7lnH/7J3+Ly8k+FmXbD9h2AxymlZ/0kRU9JueBWwHmDhZgZGdxJmeykH9sGrxDX1k43yzKK/7Z/CN6ovxs/uMk0zDUgFNwOOrcPA0PaFkid+6TVTV+7xJ3yxEOQxYX+SzqtVW+26w+X8SNEz6Igxf/zKdUYvFIu3u14qnVYMoQAVM3uUcDYhDj0aeQyDsVmMBKXmBPHtJSdBDt8pHH+OtIyFpg+TZzTM9xVmABXSEOwOcJ9cDietAfFFSVpSgtagU/0AX2uJQGO47kl1xRo2imkHhwEv417SSioTUEKMYppjLkOym99v7gnlSE6PzgkPRKN/18GJp2JIiKfFHnoNLQovR6/z7r6YRb/deezzk/a8TSWO0tU02ZuJxSLaVPsEXgByCCyRyJdaH+rYZEHB5DEokaRj1G7ELPsDGL9m3ua0nMGjTZBa8mdoM41AnZvqca2BCciedyuo8lpK1zU9PLKmYbQ+xsQPZRypPgfDjgLkzTxhAjEHRe2zyITupVkqS9aUqvR3HV8W+u/hEzTXjgh+1whUoTrOkW62VBNSWLf5QwyN6DGA6KyQRVlUd3oRZlJMqayUhS92h7xfOE6sINXJ1DpzNMUSK1UPh0PheYeKG2/b4nu4MF0oeNM0vDz0CbBmswF1S4IE6liyZdfpKXHPNr6iNZnhN9zPmDmHDdHtyYNN/Laij6Noe9tCMHNY39wrnDJB51BnWHFN01RNIu46mYvecKTQlNQivhQVWnw9CkobuwKFXzWMTIhpKavwgRMLR/a49Qe9sSzCpvEaet1leCvAAAIABJREFUepwx4R7WreseJFcZ1YV7HYT7eWufWHrrwopixbUZQlUJ4jK1ttnOQNKt23p7Yj0+DZmfk94rGpyNA15I6wXyhjbRm3MgnWTCY2qFyfVruBcvU1zqsfNGGkQorir1iuOHvvsddjUQoz6qNkKKODqaoDDjW43nSi17LmgRd9nNQTs69AO32tBqGGsO5Ix9hleJrTcFqdTMFKxWfPLKfb7yZ4YgGVd+L3mi+sCJ0DoMP7dpWaGzAqmEqUvJbU0mdZgjqnahHmI7BKouuscbjelmpCDi20i6F9nQaadQ18zAvXDo9AF7O2/eX2ilYdHhtqSqo3zDQiTdeaMYUUuWBkH3pxDiOFUsEP08ZlKS7aTkDy07d1aQUsgf2sCKzkKvbzuG0EbH0O6rBfZsu2GTOjzmU0Ahmc7rx/UgTOz6TkjZ26tXkOGAeqQMjKXyrh0naGVOvgIW5GANQebTRQN6QvmskcM14rmS7LJmx0RtnHMPie1WIXIN39OpoVZDMoVk4gFLmgYn6dUs3L8aLJCwjuiV9gils4FlH2XY0nijSsSRGI/Whmy3phoadqseey4M8KnUYjTU3EUUl4Hr2ZAtewKcXQR8MKpduKCPx7bQ0ZDpjQH7NywPv8dh10p+8NX3eHPlLq/n95j5lInP2XEDnBoGtogORLDMnW+pSavi1EZxPjiVjIpe7JltIt6mnhxamLQldWXimKkB73ll8JB3XrjM7Obqo3Xt54SgiduxT11BXSMeKjUYb0kkbHCMhsyCiczurvM9SpGn64hDCsjOCQ5mTm6b9ys2TvgC3iqthSQJc487py/KXO+5k5KeP+Hot2wiXzngYEPLjX1qIY6zgnrFFDV25kjHSrJtw4SZHaIDFryNAxscQf96RUPSJsq22mlkzHcUsFwe7J3tBC5FuSbUQ+WQWfUXD2KQQR+3McT3PGm8Iz0OR3EyTLOrIdybcvGMbJjjrRclAoZHnCmEEpmtFFs4IMVav5DBXBQlOfri8x0J4aZlq/Yanfj8vdpzcIKd1tgipaiTVm+7ud8FzoxSJzEj84T3+LNbykdEtqbXCzejfg/p9dBehq700cTg+ik+NUyup5QjYXJNmL1QY4YzXr32kNV8xhvD+1xO9jF49uKEnY1kTKU2yCVqTmXtwnBrI8q1dKc9B6eGkZ0yNAW3q3W+Mn0Jr6HG2TMVb/Vu8UZyNwqgm7YB3sa6aYXwav8+33V1la+sjZ64QH9ykz5aI8crRJUvOhd4s1it8a0GavPdG3QdbnsspucN2j7eKIw1r7WRzPAsVYvOEl3d5/Yaf8qv9UgaWuSJBCbOA8Raqqsj9l/OqXtCuge2gHw7zFFtNiVBqCOkkauh4K2EKFfAzrQlvZg6RL/VSlyjs/A+aqDuQzUQZG0VYy1+MrmQa0yM4NZXmF0dQOJ5r67Z0zy0C2oSRwwuXndN5GujnNjBOrCPKn+pOi6ZMQNTUWwo9s03kL0x9Z27595WTUuViYTY0luSqWL3S9AeqXUtu3nxdZGLEFuUiPXcVjSoQxRtyFZGtE15p/bAeypI7RcyeLaT1m6DlCbr9YTX7tk44KMWgbHIMGjw6sYq1Vqfai1jfC3B5YQdcB/0c3t87sYtvmt0h+8ffhsXRbidSlvDrTRhz/foScWL6RZ7rs/dapWJyxa0j3umYsXOeCF5iBXPTFMqTVg3Ewam4N3yCl/YegVVYS2fMkoKvn/wLT6TOhw1XpWxeu64LLQ1xT/+W/ktBpdL/njz9RBNnRU0LKI6pnOalIvt3P8PEj3aiSEHjreCHHEn3n28WfhhIxKOLwgwxHNBLwYLGgCRucNtLrT4nR7ZbJ9gA/yo84XHDX447xBrmFzP2H3VYEvItwP5rv/AhTpa6UOfZuEwRY3PEnzP4lNDNQxa27bQttYnteJyQ7Fh5ypYImgCbsVRrSSwNsKIoEURiJgHy1rnHWKoNnpMriZIWvCN6jKVJkx8fuRLMnE4PDYoEiw8Fjb/tFORrtkpm9ZSX6mYfPIS/Vs95P6D59uN8QxgRFtBEq+G0iWkY4fZnYKu0kvrI4lpzWu6qWnTjNxi0flKx2G3wkLaiaKjA27mKTcaBy2HJrYtqREOSUocG2figO3qKuQ5XNmgvLoSmJJJULipViwuhbov4d8AynUNbQp9h6bKi6tj1tIZAzOvq1aRFOQxGPXtTnJLV5gVV7Hi2UjGbCRjduoBE58xMCUpsSYaBc7XzSQqRFX0xHHJ7nO1H0S219MpK7bAqWHL11QKpRoKTRlrSGHbWBtdNTNeTB9CesZFUDH4VNnMwqSihpzQXYwNwq7zaOZlFw0Rq4uF6Fn0YotNNP0Ox8XBVPTHvv/8X5BnvIARsAgmz5GVIdXQhLTyROKGT6iGcR5tQ3Dcd9hpgk8F1zf4RChGBrUhYu4Oj/epUA1BzTzS8GmYU+1yKF5aJ33YQ/b2g1M5QEI87xBrqFYts0tC2gtO0SEL6k72ANnoKNgYGTeylF4NWz7DU5KvFOy9soL4AfnbF2x9EVPHpUfKKhDiu2li4LD+Xq+CFzk0JX3wWO0NiYkCJk2mJtpTbXCupbdMXN4yzLsIqm4XKAUtSYK+8gLl1SG3fygn+aGHrPQKLvUn9GzF1XyfYTIXrWi0hT3C/WqlTQU37S5361UqtW0NF4IT3IvTeT6YbPCNh1e4NBjz06/8Gi8n2/zT/c/yUbFGbU1LLBr7HGuUz6Q7bNocQwqk0PuQ2UaKwXM12YtEq5QvFlfZ8/3wOjxDE+rL3u7Tk4prdp830l3SYXniYevPFEbwA8+nBrfZqQc8qIbx8HyQQjeabRzrUT11j769YjUo9BQ+aWUsjfhAsjEyv4leJDQR6UkurCOc8MHarzaMYTO/gMUYsIbuQJFziU77kSQp5spl/NoKk2tCeb3E7CXotkFqqEahjavug1olf5iS7Wis7wbJyeKS4pMgsmBK0455C/bpMN8Ix8wsTPq684M5vfsZ126P8ONxe04XBtay92LC3lsVn7q8NT8cN/Dz61EjZ6UZ+BLLXpHDAk3/qmsd98ynvF28QM9UfOraPb76r1iq4YAXfyd9/mTQJ4TqosNslPW8CnZSobv74CG1rq37Bh7KIumqVoOL+s6PtB9pTNUjnedbvIvCHZ3ND0bxWYIaYVxm3C5XW7/TnqPxYY51wsVxwIihvtRnfCNldtXzF67eYj2d8kK+zcAWXEn2GJpi3jJEcJAzTRmYkkpty0Zzaih82rYSOTWkpm4HU/dMxcwlbO8OcF64W48YmSlGPKvJbO7I21qmMFHo+YqZehyw7fOWDZ3G4fJ7vs+u6zHTjH3XIzcVvTCZcp6GJjTXn2pW8aiGSKP0pGI/Rr+Ww0VG2qcfw/m29V78fLcp8yHh8DGs4IuAbgr6ad/qcc4hkrCetJXhrCBpgq70cat5S/ZRAW8Vo4EQ2Ixc1CSqW1nQJNR+fQouCzOzTR1KEz4F148ljEjQ0tgPLLVg6kD4q4aKnQr0ciTNLg57vIEx1H1IRhWjbLYwWvBx7UhHPRau5/n132QAL+VjLq/vszsYXLwMC8FJig81b+QAUap9jln47h5ZSND79n48Z08f9jnt8+IIw6a1rqgSxnVOmjqMWZS7fNos36k7YLMy5P2/2Cf/gS1+6PIdfnTjT9ooFCCVmlItE58zjvWQRgO1YSi72McV2od6ofYYo7iRmbXzedfNhD/efpn0qwMmWZ//zf1rvLC6y0+98AX+w81/xpbvcc+ttprQ227IL81eZN/1eH+6ya3JKqvZjOu9Xfq2YitbITcV+663EOk1PcMWbaXg7riEe95TzZJTEeJ4bApOo2iIznfMA1u2YhtNW5EVDzrnYh7GjG7UwprXpcZhVCl80kbAzc5c49SbC1nbjGmlppWqEeEQBR/7u5uA99De1w5Etd2IHFb/9QnosB8y0vvjJ9KUPTV01pcMh+x+dpPZhgGF7HbaYb6HtLIaKNeD4IYtofdQKVdCiakltzkh2RfSMRTr4IYECctpsFVw4ARN4JngMqVeUcpKqF7YIBXB33vwRPNYzwpiDbMryp979X0+ObzXBhyp1G2b5EHt50wcpYb7YXWwBixB634l9v82IkHfNbzNa/0H/PzVS0/cKnNeoBb6SRXFN+bRb7esVqseWULrRr6qgmdeAy5dQh2jYysesYrLg433tgd8Nb/GZzbusJpsUREY0e3AkcZZPwFO1wGLIHnG7Ibjb7zyVV7MH4Y6KbSDD8o4q7fUeTqzWWyBGRjTE/FGUKntOIc4Ik8qNu0+1+0Yg5LthF337p0Vvj1LqW5YXk0SrJuy5/vMSJn5nD3X49vTK9wvhry/u8HDvQFrK1My4xgmBSM7I9eEIkbgqTjyQ/7YTg0VhtJb1JmzTUED6Dwqb9A43IN13AbHqQM379NQBQ9tAxAWHPCFIWAdxBGnfezdr/JoKr7jlDVNkMSe/Vo5ASRLma0bio1wzslY5nNYNfb9KiBBbEMc2MJj8gNrLj7XFCywpmP3Hy7ykkRjj3AGmio+U6qVBDvqIztPpkR0ZhCDG3jeGNxnMxnHDF5zH/MLutAwT8naw9TpOr3CqcxT0V4Nl2NGUfv+QmRYHtdKpNKoV+kjzzsYFR/WH7xQO0ZabZjGCdP5GzTSqQA6s+xNexRrSduCWTS9cE95uR5nHvDLwD8ArhFuQz+nqv+7iGwCvwi8BrwL/JSqPnzce+moz84Pv8bwhT0+O7jJ2Of8SXEDi5Kbqq2lGvGs2zGrZtq+1oinJ1W708vEcdeNuFevMvEZd8tVANbslJnU3KtXmfmU7994j/t/bcj93SHZ11dI3h/yd7b/Gj+7XmCsJ0l8nCEZ5vuOegWpdVwf7vHJ9fusp1Ou5zvtqEKLktomWnetrGWTAvnopuPv/tcfsP2gRkTZ//O/DZc+hzM13OXNOEfzWPZ6JvAKngUSgRFd3Lh0WpC6PcDNRV/5pI2S55mK+fjC+c5ysRXJ51D3BJLHs8BnOuFt/gUlM0B4kdd5Rd4MbyPyq5xgjT0riDFoYudqZq2z7D6JJ2tHaqJpTxtGa2rR9Pj74XNhszRhdlmYXVLS/TB0AUAkTi6KOtCaAFbnbNFY/+4KIAfGvCKNOIkPUTAG/MAhPYdzKaaMUU8hiBOqkcVUA3p3H684cS7s1YURdOD47OAmwIKuAMRhJgdu7qHt6PFOtJkd3AgJXU92uGTH2GEFWRo4OMdkQp+azVTRyrBdDchtHbQKCNk2I4pvVBEtDJLqyPpvFw0Rq8FcV1tb7Ybu62o/37SEoIKgAeAVu2+Y9HNmV5IwrtYtltkeyWqdAMe54mvgv1LVPxKREfCH0fj/PvDrqvq3ReRngJ8B/pvHvlFfePiW5dOX7/KJ9C5vFy/y7uwyuanZTMZxtmzNUBw9U9KTqn2tRaOzc1yzJSNj+XY1jTn9VaYuXIAzTUh9SqkJ227A9w7e5ac+/Yf8o53v4xd/78dYfc+x9k2D2j7FmlCsN8Lvis9g/MqY9dGUT6/d4QdH3wwSZTEVNPY5XoVBXCA9Uy2cI4Akls//tzf49HfnVOOSf+uv/D67l1/jVv02wJ6qvnlcez0riJc4ZrHDFIx3wS6poHWk8bFmw1Ewr490h1WYdhGb6NTnDjwRh8sUlwv6MbUnQXiT72FVNqi14p/z62zqNYAbwC+eZI09M7SkqE4t+zCH+wROeF4P7tQ4EwOJPbbC03mwmaYJ5briNitskZJMYlo5biy8DTdNtRrkKLubmIaE1ty7dPGf+BANq4D0HL2VgunUopNIaKuCk68GBlNbevnjHfB5sNfiCQm2X/Nmdpstt8Ltem2BVwEspJ9NjG5dJF8dJsjRzVoNTEEmjuvJHi9YR69XIWnaTkw7Tr38VG1WC+N4D08S12bo2qhVDBilbysKb9sxhDBXswo/H+0MD/YCd+HarMFifVccJBOh3E+DLvXBq/MpeS4f64BV9RZwK/68JyJfA14EfhL4S/FpPw/8Jh/zR2jqQg9mQ27WG8w0ZcUWrcJL4VPu6ypbsZY7NGFL3TCe180Eh3DHwZb3vFtf4lvF1QUGdOUTZpKGuZExnz+UkoEt2PszBfsvh120cVCtemS9xFil1y/JkprX17e4lI95ubfVji8MCz4qoHQWv1XfOuDGMa1eyVm9kgMFoxUhf/kS+/WUu5N3AB6cxF7PDB9zrR2msNOqWjX9bx/zJs3CddrYysyHrh+8Vxwgi+XSJyeIpiSSMtARBVOAdYKt4LRtFhnQ7e42OuL2WnuCyPcRRbBGevGwvuKPwVnaTNIMM+yjgxypgCLUgNU2Nd22KhG+l4YfwnqQueONjlYN855xCQ67TdcrqJMQdRjF5aEVSVx4zGVQ90K24nE4N2tMBMkypNcjy2qumIKJzykjd6SJYLto0tHzCWyywICG+cQkI56ZZnxx/Gq4L67+CZvmNql1uCvrWMDduXcsNvSp2KzTadAECI1Axq7rUdTJvHtAII3iGvURw2K6YwiPgiE856CCVtf5ijScmqDSZseG0tnWFzXl0aaT4VRY0CLyGvC9wB8A16JzBrhNSFE//vUesl3l3t4KX5m+RCqOzWSMQwKxyVl26z6VGlaTGWvJtE399qTCJYZUaiY+Z6Yp78yu8c74Col4VtMZibgQ6SGt4Ma+6zH2Oet2wt/7kX8AwG/ufZpvTS7zxuA+nx3cZGSmvJI8JBVP1RCyfJ9tN4xsa2lJDVWsUTsk7kjn6VeI80slsKFvf1hRfvs+6Y++QfEvxwBNuHwsez1LVEfUeh+HRv+6u+AaNN/3YCTsVZhp+BtookGmrYmAO2SkozDVMXtss8YmQHLSNfZMICH61ST0qDaEKzUSvsOTON8DHTUwj/KeVlXrtG1mhn24doV6vUcyFfyuRXyUm6zBxnt7u6dTCReGgEtlQR4xMJ21jXyDLKe2dhcFaqGuLKSKGzlkZkn3AkGu7sc/zgnS92e5xsRazMoQHQ1YHcx4Kemz5WftsJTM1K0zDWnoRxm/YYTqoo57+D90auzVfX7n7ie4vzdk8ImSt9K7DPOS8etX6PcT7M7uiduRnovN4mbk4ObJEjTm79er7FcZoziIAQOZqUOd1qUH+oHDYgtSu+H3Whc3KQ1CUBGG6tSdyLdNbTeZKROyVdluONdZnZKbCuN67fOflmh67FUrIivAPwZ+WlV3pUusUVUROfQ2IiJ/C/hbANlgA1NCXZu2Bul9YNNWPrBnjXgaOkUz6m7mU4oo9m/jAICZpkxd2hbQu7l9g5IaR868b8sQxDFScbySh0D0xfwhl+w+A1OQx+eV0cmOo5Nv9KS77U+NJmjlAyGrQVOnTqWmGtf8z//JLV77j/8qeqe/YJPj2qvH4Lh/no9Fk0bv9v+e6PXHJGU5OjT/Ns3YWZyPmR1Xa82X+T3e4s+SSLrgmM7CZmF3fsRDTxC1HvYercSlNWGjcsJWkSex2VPby1q0n7Us0dYM3elfcuB3Delp7R4jRrtz3sv8tTLfrElt8GWc453EdDbx/WKNWdMwEU0/Jr165mtMDDIY4FZ69JI9UrFA2MiHsrh/RICjiYobOUrTaSE8eC23Ih7GY+38eXlSMx4I6SAhOSEb+rmvsU4EDHN95z3XY1YlrHYi4KO+b/f3g9ORDuLgaw4/p5CtEa/YQrGFUPv5QJ9jvccxcCwHLCIpwfn+gqr+Ujx8R0RuqOotEbkB3D3star6c8DPAYxWX9LetmOrSvAqbFcrbJUDjCjDpCA3NZfSMQNbsFMP2Hc5pU/YrXoY8fTtZdJOxFX4hJ6tyE2IknNTs2Jn9KRmLbY2NZONLJ6b9QZWPK9l93kzvx3ZypZtN+B2vUalCR9V62E3GiO/nbrPnWKVSg2lD+dduqQlAXgVEuPp2YqerXipt03fT/mF//wbfPonXuHBj3yKB78v2NEItzVLoz2PZa9V2Xw2lGGZN+sfhsPqScA8BR3F3o+eTdqkyII9QsuT4NMoqnCQTXIIvHq+zO9xnVe4Ki82h+uTrrFnZjNrAzGqGY8ZSUJNm03D03gSJ9zeF5oIGPC5xfcS5AQ76Se12dPaS/p9Zpf7FGuRpNYwnaMsnya0kYE2+9Nmo9Gk7CCq2zWCLYb23moUbIxAPCS7Bj8xuNUaO6pwdeAVaKKB5IfgRj2S9TV0OpsLczwjez0LmzUw/R7la1eY3Mi50Q9BpIstlV3MBTh8u7EfSUWGZ2hK8DxCyAqp6UC0/OTqfa7093k9v0dPPFf6+9y9YUBTevnRcpcH8dzXmNeFDZORMG93tw6toLt7A67WobWKmF62vnO/OWyHfIBM+ihZVBacfXNMVai8DSMQJRBIkxn0tzzJTJiUafAlB++DT7ER/1g3LuGO8PeBr6nqz3Ye+hXg8/HnzwO//LHvpUoy9bjSsO9yxi6j9DboFHtLHW/yYbSWUPqEqUuZuYRJnTGuc3brnHGdU/gEr4Y0incnphGZ0HbB9qRsnW8gUWWMfU4qNSMzi6nVoL+67YZs1Ss8rIbcr1bYdzkTH9LYY5cxqef/pnXKuMrYLXo8nPXZnvXZKfpslwP26ox/9D99hY3X1/iBf+9TQCB4DT79WYBLJ7HXiXFMIYJjtxiJnw+sOJAnnRNGHv3MtuXpmPURVeWrfIEhI16VT3Uf2uaEa+xZoZGXO+hgD0slPykahx56gWUeBR/n/M7SZtbgMxOnwBw4rw65Su0BkhU8erMytAStg9rhzfuYMjKsVbDWx/nC88/yCfjUIHl+5OCTc7PG0oRqlFCMhJ6tcepj6WZRxGYxAtZYClLSqJKVRS37JiLuxMYArCZTNrJJy6Pp24q6H1L2ch7XWNOC1al371c5rjZz0mJn7Rw1sa1Bw1s5jqjQQVKWI5ASGr6CnXmSmbYKW88Sx4mAfxj4d4F/KSJfjMf+O+BvA/+XiPxHwHvAT33cG8msov/OfQZ/+gL/T/Y5Xr66xV+6+g0Kn/CgGlK4hG9OruBU2K9yJnVGYjyJeBLjSI0jMzV5/GdE27T0wJRt7XXiMyqxiwxfNeG4Wj4sN9v2miIKVBQxum1qvLtxkpJHGCUFXsNMXY+wqz3K2lI6y7gI51hlhrRO2fpyyVf+yQdc+uQaf+9v/hbb1T/n0g/8da5+34+x/c9+czW2IR3LXs8aB2f7dtGynNU8snAtipdFpZ3muY04SiA/BHs3NmzbTT4GOzzgNu+zwhq/r78KwCf5HATy3796kjX2zGAMPjVzlrMy72uNOEn0exiBq6kBuxSmV1N8Zhgkx6sKnanNRBbJVIA4wZRzhxgi4VDLFQ84mbdddR1t6pHEo5IG+zqgNqhRqpHHVEL+UDClUF6GjdGELS+43QRjBEy4UdZDS7YygLI69JTPyxqTwYCHn0qZvKBsZmPeryfcdVfDXG0To1qdtxulUjIy09CCieJiNwgGehJajSaas+t6eExL5rqe7+A1THWrEDbTMbPrNaZKIDtez/Rp26yJSlNxjF3GR/ur6H4C9fw+3r2nQ6gJNziob3+Ukz6MfOWtgA0kLwBjPFU/KK/l2xWmtlS1XWg5BZ4q+oXjsaB/5zEf82Mn+TCta/ztuwxv3aBc77Ez6vFStsWe77FdDygRHhRDijqhcAmFs/SSmlEWdnGJhMHJjQPumWremxv/MI2T9WLwsfHcEeq1O65P7UONt47kqoY4NG+fCY6m9pZKDblx9G3Z7k4rnffqVc5QVRZnDCJKbZThW2/wl3/jv+TN1Xu83r/HP/z2n6P6zcvEuRF/qqrffxKbPUt0xw4ehqNS0aH29PiV1q3NLMi9ycc7qnW5zI/zNx99QHGqeqI19sxgTUipds69jX67Ud1JnbDO/w8s4KDyVA0FU5kwg/gYOGubtbX9kAEOm4lItPJpJxJuUtReWsc7t6Miicck4XpqjzdZgZ4HY7CFkIxDtmAtn7Gf50xSxTc1AA3Tk7SXYo5wLmdtr/bj8pTZFcVdL1ixBVs+azkmVmM3gsyvxVTCfa7reJpYN2T5Krw3jCUPLf9xwa7ZaSi/SUWlhr6tMKOKesUeezrbWdqscAnjWYaZmXlm75BrrbkXJ/G+lhjXpu8P1mkX5CrjPaqO9/Ms6q8372NMKJ95K5jCgVN8M7u6Lc0dfV7HxalLUWpVs/71Cdlej4c7l/hf9v51BsMZ33X5LsOk5FovyMntVD12yx4ApbPUPqSpE+PIjCMxLtZ+w44k7bQMQaONOs/vQycyo6Giu4XUQ/OaVuw71ndTcVRqI+nLhF1XConxDLMqROI2ROiXe/uhV80lfHX/BbZur/Hq1yqS6RnKC/o5C/rgDnLxabLgpJsoFuap5oOKWu3ziOIbKq2gh3aINBcJYgTfy6hWU1zeIRsewslqSVSP+54dh9063+Yh3zCHlWSqcJ5lKCM0Tah7BtcDnwQSlakgmUC1EpSw1EZ2KE2kH1jL3nYkKFUwiZKk9eLza0Ezj12rcYVFXEY6UczMsF9l1LUJKehEcYniK8E1Q9HPu+yptVQrysrqlKvZLuum5Eqyy0vZFqk4RjaID227IV6FVTPjZbvPPx2/xc+/9+fZ3h9QfDREFP6Nv/gF/tPLv0VPagamYOZT9ny/vUYtysjMGBnHS9kWmxtjHuxkJxJ8OU00IhhWfCj17eekE0FqF+4+PvB+dqseD2ZDah9ag8Jr5zXdJmnVpIwbjthhpKxu61GTxctNHaQqU0GNYvZLjBVcnXf4LqZlQYe+9ufMgn5W0KpEfv/LDMUw+p63ePj+Kruv9nnwo2OGKyUv9R4ysjNuFuvcsyvsVzkPiwGqwm40aGKCelVmXDsdo5EoS8w8zdqVLDOibdq6cdpNJG3Fk0vdMg0PwqJBbYsRtRoy68isYzMfkzbOCiEzNW/077NmJ/zuzif4xvYVeh+kDH73bdzO7ilZ+FGID+lze3DodAeuUbGSZsR3cNpN5NsxRgclAAAS90lEQVQdk7bwOuSROnDQiZZ59HtQXvG8i+aLwQ1TylVL3XHATTtSu/GNJdyFZvyDX01CpHhwGEM3CjYVpGMlmbggknDekViqgVD3QquZGjBl+A6uL7gsspujJKWdhelITa8wQku4StKaPKspUtr2JKkF7cHm+j6TIkNcRrbvsVPL3izH1TaKewCZRyvBZQlqz78D1jRBVyteWtvh5XSLTWOY2X2q7H5kQAdeyrYbMtOUdTPl9XSFP9h9g9n/fY3Ltx2rv/ttsJZff/VT/A9Xf4uRVGxSMfaGe75aaBG8ZArWjOW17D5vbd7l93eG59YBNzAo0zqF3ZRkLO01IU6YuozdqsfWpE/lLLNZinqDqizeVhQ0RqzSaE52L+Xm5+iwbRIGLfSSmkFSohozOQbM/gScx9XzbpY2vX3MMttROJu/hCqow+yMGdzuo5Lx7lde4FsrV1m9PGbUK7jcH3Olt4/NZmS2aSUK0WlqXBvBdmvB3RabNk0cI1eYR39NJFypbW8EE7L2dYe16RSREFa6kL72KmTGkpiwW7s7XkFV+EpyA4Bbtzcw9zI231e0PKVJLceYh9qVnTzssab+O9ee1QX1K2IP9GF4hPAgLIZ7cP6db8QC2cqw4FgXot2jHC/z44dNQmrbmGJbjngNQh0XQSvbmHaa0bwGHLWbtan9Rv3n2APc1M+b55sqRP61C+PjGhGOhY+Ja0ecYirFVEJVJSEV2GGSo0HNzvdS7McIcpw1pKoxOykfbK9z79oIxy1A2t7fBpnUeJn3+lbeYkvFFh6tKnAe78NAAQc0rbJducqgqW+o1LPtBtybruCmFvFnPKP8GPBInH7VOSghxZyIwxrFe8UYRcXT7YRqnLE2EXBHmKPV1WnWVud3kTCSMDeOJPG4HFwW76nRZk0NuPFFoczy5CNXz2Ac4dxJuA9ukt+5Ry9LufwbQ3TYZ/e7LzO9ZPjyDxf89c99mY1kwo1sm6EpuGJ3I/sv/FVScWQxbZwyj0S7UdkD3+fd8jI+Klg5DN+cXWWrHLaOufAJ+1WOR1od0oOo1VLUCbUaZnVC5WxId4jyYHsF+eYgiNHfV5KJ8slvT0m/fROdTnHT6aHvedoI6fXDI9lmEpIV/0gmoOuED0P3sbk4gMbWlBgBPsPvcRoQ57GVzgUmulFvV0Ix5rua+mcrW9k8HGujTU20WwP1aRjLF/oMFVM69AJsUHyWUI0kzvkFRLEFZPueqbf4vg8GM4o6QbzBlhKdc2wtmgaRllmRhNcrh6bxNWYI7NRjZzCdpmhl5qMKK4PUgsuh2MywO/1jbUTPCjKesvoNw2S8xpdfepm/Mvw6Vbzu2iwUQUoyFdfe10pvsQWYwoeI0IRpPKUqhcJMbRQRCq8vYzqhUMuer/hWcZVv3rlMei89kqh2JjDde8f8vlM5iykCsQ8XjqlVBqakZ+s2KGs0nNf6M/KkxnlD7c1CCrqLg+noJl09KTKcCv2kYj2dsNIv2FlV0rGA82hZIaIMTUFPqrARMD6UYJ4i83KmuQit6yAMPgG2dzC9HoNLK9gyZ+duzpe2XmQtm/FRf40VW/Bivt2qYtnYlA5hTNcg0u0nPl/QUL1TrfGt6RWquLBrb/lwvM5OEerLXoXaGWZliqpgjF+wZXMdqwY5PFVCCszNUxDspIzuCelYGd52pOOa9OYW9a3bz9V+j+Com06snXR7DQ8yBJu6bfOMUP9t6uoyP0ajxrN47EhcNM8LoB4pHHbmMSvx+7Xp9APO99DXP+atm6gXFmQ6TekxpWt32ucaUWK0XU4qi7XwpvYfMweitJmmgxsUdYJ3ttHWiHKVCjb2fNrYJ5zEF3kJ/9o3CMfUhprdcXrOzxJaVfQeeuq+YbvsY6XJuoVdXDcz1Z2K1MzFbQM9DRFwoVA2EpUdwzaZriBOBDuuj9vOyHdDTfVcQeb3kvk9Rh5pSzOlcK8csV/nlC6wkqsq9OwWdXBlTgUXU9Kus04OaoU0fl9Ew0amtjhnGNcZY5dTVElk5WvM2B6QB+WCkrAetzP1ZUXyJ++T5hlvfnCJ8v+9zG4ibFvB9QyTKwaXC64fWjdMHbSlfQblKCzOdFewZYxIPGT7Sv9B3d4ARMFUnhWv7Y1SVOc5HDnCJLq4+FlYGAVmdxoW9nQW2N77h4sBnDrUk0yEd/cu8dJwm8tpILkFic05W7lRsErFtSl+19mZd9uUPKFhHSCPOaKuc2/0oFtndb7viY9AncN+eJfh9gA+c5XJtRSfAFH20MR65vwFtAXh+RoJ/z2SgTfzyLGxjamU/MNtZDzFnafo5AioNbgskK1MlNL0qVANQ0QPgFFM6kIngkLs7ojjCoMNXA4UBlcLKYRre6DoiiNfKbg+3CVPBty+vEEyTXC9eV1PJaS3pWklSYJwgmbnu77pt7bZ/O0PWbu+wfs/vsE1m9OTkpR9Jppw260y81k7V7zbDyzKgp54VSS8W68xlJJRbLOYxT/AqgmCRFdMzabNeXvnBjd+yzC8PUW3tk/xGz8GYkLftoQyxcyFmeKFJvMRgRFalqy8Z/i19U/PS1uVwYyDQtqDZDAvFTW132ZTaA6QQbs/N9dpFQ6+M864tbbK5MMVLr0L/QcOnc1ABPXCTFOqOCq3OcenUcQ7X6vVO9zDONXq9p2FkzODAaPXX8YPMqrVDNcz2JnHTmp8zzK7FBZe/16JndRIFaIJ83Cf+sObzzUlpXCExtQ5gFdMLYyrbD7DElrn65jvOL0KTgxp59s0DredFtL5ufl9TnrrpK2b7euz711//lBF9/agKLDTy+3AAB+HDWjTctN9CeFiDDvmcOxQJTyJwhHJ/D2MA9kbo9NpkFI87zBBz7lpMWrtk8gCIUVMDG469XSVODM4CbVicfPpT01ULXFMaM/W9JMqjLXsB8LX/M3n79vUjxdKA+cUWpXUH3yInRXszi7jVDHA0HgqH9PQx9mxqqLOsOf7gYja9r427UuOXBxWBKfKg+mA1fcmJHd2cEXxHL/hCRGZ6xKVqJouinZNtBwLJd9W0jtp4B/0PKYUkrEgXuaZF5XFa1OiA+6+14ESEQSCF0BpUsYq5NuGfMeT7dYh5R9bt5q/j2/O8SkDjPPlgB8DLUvkzn1smmLzQKWXqoaqhjQhux3k1WR/CnWNeg9e8bPZua0HnQqM4DJlNZ+xnk5Zs9Mo5B4IVmt2Qs90xz76VtykafR/RPIOYRYnUPXizvtmtcndapXcVKzZKYVP6K/PmNYG10vmC+0c1+e68GWFOE/v3Qdc9ZvUQ8v4WhIu/qSZ7DNPwzas5gWCUEMsOkDUSseAh8F9T+9BRfZgit/dC+WYx2hlnxe4XkKx6SFR7DhEuI1TbZdKc0M0oc/ZJ7RCG3aq5Fuh97laFTS2LamBdEewsx7T9Yy37XUqZ5GKVuAj6dW40qKVhTrcgO1MGH3gWHl/gr27TX0B1pdOJthf3eCzd/4z/sLn3uHvvvJPSE1NlWwHLXrNcGoYRgJRz9bBXsOELEaNSV7zWvKANVOxbgxjLbGEbotrtsKK8D/e+nF+4523yL80YPPm++jeHlodbx7w84aYOIwhTVAT+DSNnn9mXRgRm0voyS9LNr+0zfD2EDWCTyTwNIoDohgHSI9tr/oBPNoOGH6p+xbXs2Q7JflHu8hkhpvOMCvDR3Z3qfG4PIxc/biZ50fh4jjgusbdf/DxT1ziEaiF1WzGajJl1UxbgkYqjteye0GWk0bGM/6PMjSHj//2QNU4k7gmLUqllqEpWLcTiixlc2XC7TLBHxRHuAhO2DvUO9z7H5LeuUd+7Qp17xp1XyhHhJpjQptybQhWC2loOin4GCmKg3RPSafK6Fv7mD99Hy3LsFG8IHC5QVcrxCq+yLAuENUaBawGQqyx2UC+0jo8nsxg5VZFsZ6w9wkiWS9oSaf7kNxT7NSwvRZuesM62NGnSi+vmHlBscGW+0IyhuHNKeadD/HnhPD4cfDTGTd+7S6Xv7TC733+kwxeTbFGcBRUCntaxdnj4QILUpISpj+ZeP1mNS8kNSuSMTAZA62AEN1u2hynym+88xZXfrnHyocT3O27J56C9FwhBrIUTS2tXn1kGGfG4XOPT0IaResa/dLXOJ6G15Oj60YXclErQ2CeYTDiscbjs6h3fxFJWEucArySTIT3djfYLXvcK0cU3rJf5RhRLuVj+jZEwF0hkvDSwxdVV7KzSTvfnq3ysBjQTypW0xn3pivc/HCTZCsl3TtwUzzvzrcD9RoyKuMJw5tTfG6p+wk+EVxPcFnYjbuMNg3ahbhQMxYHSaGYWkl3a2zhsQ/28GWJuvMf9XbRuzNh9YvrYTzcjmIqyPdq7EzpbVum91J8BtUoC5H+HSWdzHkT+Y4jvzMm2c/YGA6o+ym9bU8y9djSYwpPfyshmYSs1uimIxk7bJkyvbPGSgnJJH7ursPOFPtgHy2Ki2NL9cjuPimw/sWr/MDmf0AvqxjlJal1jNLQfvk9o5t8pn+TP7zzEv17nt6DGqoSxDC5M+T/fPh9rCUTLtl9Pqo2+N2Hb7BX9tiaDpgUKf0vDFj5cEJybw933sob6mE6w0wK7HjEnf0VCpfwIB/ywcN1sgeWbIeQ5TxrOIe5l/FL978vzi0w3N8fkm2bMK7wCc9x6YC/w6HOkW/B7Zsb3EnW+XpyDa0NOo3j3ewhdVqj4AUp44Sarr9sojknC9Ge1FHpKFF8XzFTYf3bhmxXw8XfntDFcb5AiIQLh7t7D3mwhRUTdslGMKuryKCHDvvU6300NVSDZG5PhXRck+wUSFHB/e3gzKdT1Hlq5y6E8tVB6Nvv8OK7QZRAy2qBud0zhjXArI5wL14GwH70AB1PkEsb+LUhZmeM+/AWRj2XvxhKGXg/b8HySmaElSjLqXUNXumlSajFed+uo6Zm7qr6YtlSlfr2Hbhzj+sffIT8Yh8ubbD32WvMBsLt64Z6CH/w2uu8eOMhe1/d5NrXdjDb+7jpDMkyVr+e8H/0f4S0X7EyKHh4f8TaH2f0Hnqu/PFDuHMbnb6LFgXO67mzj9Y1bneXZNAnf3CVrXurbKdDPkg2cLf6bLwXSVDnoGatVc3oXeG3R9+FXS3ZWJ2wuzVk82Y4R5k8WQZr6YC/k3BEarcRw49UKbQOTe6BxBIlI9sn07ISpWgE9LushUh0cPNfIdb3fHgDrcDUgqkUW+nFaK05DF17qgZH0EVRhNpPmmCqHA8Yp0FEoN2YKFI5pKhChFbX+LI6dzfDk0DrCr8fezMbm4iElKJG52gtZhoyKzor8NMZtqqh9lA7tK4Ot2n3cw7ceM9V+vRZIAoS+ckEJhOstaT766hYkllI21MaijoJzPtouyD67MOx0uASS1knUBqSqZJOFNneo74gJTttpoK52E7mTZAudWBqXbynHdYjekowtQaVNhdbnBqBGccT3+PkNBv/ReQeMAbun9qHPjtc5unP+1VVvXLcJy/tdTJ7wdJmPNkae+8ZffZpY7nGTo7lGjsZnqu9TtUBA4jIF85yItCT4qzOe2mvi/XZT4OlzU6Gpb1OjqXNTobnfc4XsUtziSWWWGKJJS48lg54iSWWWGKJJc4AZ+GAf+4MPvNZ4KzOe2mvi/XZT4OlzU6Gpb1OjqXNTobnes6nXgNeYoklllhiiSWWKeglllhiiSWWOBOcmgMWkb8qIl8XkXdE5GdO63NPChF5WUT+PxH5qoi8LSL/RTy+KSK/KiLfiP9vnMK5nHubnSd7xc9d2uxk53Lu7QVLm50US3udHGdiM1V97v8IEpvfBN4AMuBLwGdO47Of4FxvAN8Xfx4Bfwp8BvhfgZ+Jx38G+DtLm50fey1t9p1rr6XNlvb6TrXZaUXAPwi8o6rfUtUS+IfAT57SZ58IqnpLVf8o/rwHfA14kXC+Px+f9vPA33jOp3IhbHaO7AVLm50UF8JesLTZSbG018lxFjY7LQf8IvBB5/cP47FzDRF5Dfhe4A+Aa6p6Kz50G7j2nD/+wtnsjO0FS5udFBfOXrC02UmxtNfJcVo2W5KwjoCIrAD/GPhpVd3tPqYhF7Gkj3ewtNfJsbTZybG02cmwtNfJcZo2Oy0HfBN4ufP7S/HYuYSIpIQ/wC+o6i/Fw3dE5EZ8/AZw9zmfxoWx2TmxFyxtdlJcGHvB0mYnxdJeJ8dp2+y0HPC/AN4UkddFJAP+HeBXTumzTwQREeDvA19T1Z/tPPQrwOfjz58Hfvk5n8qFsNk5shcsbXZSXAh7wdJmJ8XSXifHmdjsFBlmP0FglX0T+O9P63Of4Dx/hJBi+DLwxfjvJ4BLwK8D3wB+Ddhc2ux82Wtps+9Mey1ttrTXd6rNlkpYSyyxxBJLLHEGWJKwllhiiSWWWOIMsHTASyyxxBJLLHEGWDrgJZZYYoklljgDLB3wEkssscQSS5wBlg54iSWWWGKJJc4ASwe8xBJLLLHEEmeApQNeYoklllhiiTPA0gEvscQSSyyxxBng/wfZOVxEYl4wqQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}