{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "colab": {
      "name": "Copy of 011.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna985/pml-1/blob/master/course/Problem011_ClassificationError/011.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "F6nZ8jbmhzlf"
      },
      "source": [
        "## Categorical cross entropy error\n",
        "\n",
        "$\n",
        "J = - \\frac{1}{N} \\sum\\limits_{i = 0}^{N} \\large{(} \\small y^{(i)}\\log\\left(\\hat{y}^{(i)}\\right) + (1-y^{(i)})\\log\\left(1- \\hat{y}^{(i)}\\right) \\large{)}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNlRCXF2hzlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15904d7-24f9-47e2-d6b4-9a029fc95db4"
      },
      "source": [
        "import numpy as np\n",
        "Y = np.array([1, 0, 0, 0, 1, 1, 0])\n",
        "\n",
        "# Follwing are the corrosponding Y_hat values from 3 classification models\n",
        "# TBD: Arrange the models from best to worst.\n",
        "Y_hat1 = np.array([0.99, 0.01, 0.01, 0.01, 0.99, 0.99, 0.01])\n",
        "Y_hat2 = np.array([0.01, 0.99, 0.99, 0.99, 0.01, 0.01, 0.99])\n",
        "Y_hat3 = np.array([0.99, 0.01, 0.01, 0.99, 0.99, 0.01, 0.01])\n",
        "Y_hat4 = np.array([0.99, 0.01, 0.01, 0.99, 0.99, 0.01, 0.99])\n",
        "\n",
        "total_error1 = sum([z[0] - z[1] for z in zip(Y, Y_hat1)])\n",
        "print(\"total_error1:\", total_error1)\n",
        "mean_squared_error1 = sum([(z[0] - z[1])**2 for z in zip(Y, Y_hat1)])/len(Y)\n",
        "print(\"mean_squared_error1:\", mean_squared_error1)\n",
        "\n",
        "total_error2 = sum([z[0] - z[1] for z in zip(Y, Y_hat2)])\n",
        "print(\"total_error2:\", total_error2)\n",
        "mean_squared_error2 = sum([(z[0] - z[1])**2 for z in zip(Y, Y_hat2)])/len(Y)\n",
        "print(\"mean_squared_error2:\", mean_squared_error2)\n",
        "\n",
        "total_error3 = sum([z[0] - z[1] for z in zip(Y, Y_hat3)])\n",
        "print(\"total_error3:\", total_error3)\n",
        "mean_squared_error3 = sum([(z[0] - z[1])**2 for z in zip(Y, Y_hat3)])/len(Y)\n",
        "print(\"mean_squared_error3:\", mean_squared_error3)\n",
        "\n",
        "total_error4 = sum([z[0] - z[1] for z in zip(Y, Y_hat4)])\n",
        "print(\"total_error4:\", total_error4)\n",
        "mean_squared_error4 = sum([(z[0] - z[1])**2 for z in zip(Y, Y_hat4)])/len(Y)\n",
        "print(\"mean_squared_error4:\", mean_squared_error4)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_error1: -0.009999999999999972\n",
            "mean_squared_error1: 0.00010000000000000007\n",
            "total_error2: -0.99\n",
            "mean_squared_error2: 0.9801000000000001\n",
            "total_error3: -0.01\n",
            "mean_squared_error3: 0.28009999999999996\n",
            "total_error4: -0.99\n",
            "mean_squared_error4: 0.4201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUwtlhkgzEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d57329-fdf8-4dfa-f6b7-fe568fcc2ef8"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "Y = np.array([1, 0, 0, 0, 1, 1, 0])\n",
        "\n",
        "# Follwing are the corrosponding Y_hat values from 3 classification models\n",
        "# TBD: Arrange the models from best to worst.\n",
        "Y_hat1 = np.array([0.99, 0.01, 0.01, 0.01, 0.99, 0.99, 0.01])\n",
        "Y_hat2 = np.array([0.01, 0.99, 0.99, 0.99, 0.01, 0.01, 0.99])\n",
        "Y_hat3 = np.array([0.99, 0.01, 0.01, 0.99, 0.99, 0.01, 0.01])\n",
        "Y_hat4 = np.array([0.99, 0.01, 0.01, 0.99, 0.99, 0.01, 0.99])\n",
        "\n",
        "mean_squared_error1 = mean_squared_error(Y, Y_hat1)\n",
        "print(\"mean_squared_error1:\", mean_squared_error1)\n",
        "\n",
        "mean_squared_error2 = mean_squared_error(Y, Y_hat2)\n",
        "print(\"mean_squared_error2:\", mean_squared_error2)\n",
        "\n",
        "mean_squared_error3 = mean_squared_error(Y, Y_hat3)\n",
        "print(\"mean_squared_error3:\", mean_squared_error3)\n",
        "\n",
        "mean_squared_error4 = mean_squared_error(Y, Y_hat4)\n",
        "print(\"mean_squared_error4:\", mean_squared_error4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_squared_error1: 0.00010000000000000007\n",
            "mean_squared_error2: 0.9801000000000001\n",
            "mean_squared_error3: 0.28009999999999996\n",
            "mean_squared_error4: 0.4201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkt7jmkGhzlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f354f9-252e-4e1b-a14f-d9d3da2375b9"
      },
      "source": [
        "#TBD For above Y and Y_hat values compute categorical cross entropy error using sklearn library function\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "Logloss1 = log_loss(Y, Y_hat1)\n",
        "print(Logloss1)\n",
        "\n",
        "Logloss2 = log_loss(Y, Y_hat2)\n",
        "print(Logloss2)\n",
        "\n",
        "Logloss3 = log_loss(Y, Y_hat3)\n",
        "print(Logloss3)\n",
        "\n",
        "Logloss4 = log_loss(Y, Y_hat4)\n",
        "print(Logloss4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.010050335853501449\n",
            "4.605170185988091\n",
            "1.3229417216062413\n",
            "1.9793874144826111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxJwkAPfTYV4"
      },
      "source": [
        "#Solution\n",
        "#This was just meant to be inspected visually (0.99 ~ 1 , and 0.01 ~ 0)\n",
        "#Y_hat1 is closest to Y, (All nearly labelled)\n",
        "#Y_hat2 is worst, its exactly opposite (All mislabeled)\n",
        "#Y_hat3 has 2 mislabels\n",
        "#Y_hat4 has 3 mislabels\n",
        "\n",
        "#Best to Worst (Y_hat1, Y_hat3, Y_hat4, Y_hat2)\n",
        "\n",
        "#Log_loss function below (or Cross Entropy Function) quantifies this\n",
        "#Though looks hairy but has simple iterpretation,\n",
        "#It has very low value when predictions are close to actual labels, \n",
        "# and large value when they are apart. \n",
        "# Mean squared error(MSE) wouldnt help here, because when we are off by just 1, \n",
        "# We are completely Off. MSE would still be very low, but we want it to be high\n",
        "# Log loss does that"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7nOn_e8TdNp",
        "outputId": "e5206b40-1da4-4958-fd11-96d61e8af181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Solution\n",
        "from sklearn.metrics import log_loss\n",
        "J1 = log_loss(Y, Y_hat1)\n",
        "J2 = log_loss(Y, Y_hat2)\n",
        "J3 = log_loss(Y, Y_hat3)\n",
        "J4 = log_loss(Y, Y_hat4)\n",
        "\n",
        "print(f\"J1={J1}, J2={J2}, J3={J3}, J4={J4}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "J1=0.010050335853501449, J2=4.605170185988091, J3=1.3229417216062413, J4=1.9793874144826111\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}